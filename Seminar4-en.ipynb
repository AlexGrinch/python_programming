{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theano, Lasagne\n",
    "and why they matter\n",
    "\n",
    "\n",
    "### got no lasagne?\n",
    "Install the __bleeding edge__ version from here: http://lasagne.readthedocs.org/en/latest/user/installation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warming up\n",
    "* Implement a function that computes the sum of squares of numbers from 0 to N\n",
    "* Use numpy or python\n",
    "* An array of numbers 0 to N - numpy.arange(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def sum_squares(N):\n",
    "    return np.sum(np.power(np.arange(N), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 9.51 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\ipykernel\\__main__.py:2: RuntimeWarning: invalid value encountered in power\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1002170466"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sum_squares(10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# theano teaser\n",
    "\n",
    "Doing the very same thing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import theano.tensor as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#I gonna be function parameter\n",
    "N = T.scalar(\"a dimension\",dtype='int32')\n",
    "\n",
    "\n",
    "#i am a recipe on how to produce sum of squares of arange of N given N\n",
    "result = (T.arange(N)**2).sum()\n",
    "\n",
    "#Compiling the recipe of computing \"result\" given N\n",
    "sum_function = theano.function(inputs=[N], outputs=result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 756 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(662921401752298880L, dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "sum_function(10**8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does it work?\n",
    "* 1 You define inputs of your future function;\n",
    "* 2 You write a recipe for some transformation of inputs;\n",
    "* 3 You compile it;\n",
    "* You have just got a function!\n",
    "* The gobbledegooky version: you define a function as symbolic computation graph.\n",
    "\n",
    "\n",
    "* There are two main kinds of entities: \"Inputs\" and \"Transformations\"\n",
    "* Both can be numbers, vectors, matrices, tensors, etc.\n",
    "* Both can be integers, floats of booleans (uint8) of various size.\n",
    "\n",
    "\n",
    "* An input is a placeholder for function parameters.\n",
    " * N from example above\n",
    "\n",
    "\n",
    "* Transformations are the recipes for computing something given inputs and transformation\n",
    " * (T.arange(N)^2).sum() are 3 sequential transformations of N\n",
    " * Doubles all functions of numpy vector syntax\n",
    " * You can almost always go with replacing \"np.function\" with \"T.function\" aka \"theano.tensor.function\"\n",
    "   * np.mean -> T.mean\n",
    "   * np.arange -> T.arange\n",
    "   * np.cumsum -> T.cumsum\n",
    "   * and so on.\n",
    "   * builtin operations also work that way\n",
    "   * np.arange(10).mean() -> T.arange(10).mean()\n",
    "   * Once upon a blue moon the functions have different names or locations (e.g. T.extra_ops)\n",
    "     * Ask us or google it\n",
    " \n",
    " \n",
    "Still confused? We gonna fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Inputs\n",
    "example_input_integer = T.scalar(\"scalar input\",dtype='float32')\n",
    "\n",
    "example_input_tensor = T.tensor4(\"four dimensional tensor input\") #dtype = theano.config.floatX by default\n",
    "#не бойся, тензор нам не пригодится\n",
    "\n",
    "input_vector = T.vector(\"\", dtype='int32') # vector of integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Transformations\n",
    "\n",
    "#transofrmation: elementwise multiplication\n",
    "double_the_vector = input_vector*2\n",
    "\n",
    "#elementwise cosine\n",
    "elementwise_cosine = T.cos(input_vector)\n",
    "\n",
    "#difference between squared vector and vector itself\n",
    "vector_squares = input_vector**2 - input_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Practice time:\n",
    "#create two vectors of size float32\n",
    "vec1 = T.vector(\"1\", dtype='float32')\n",
    "vec2 = T.vector(\"2\", dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Write a transformation(recipe):\n",
    "#(vec1)*(vec2) / (sin(vec1) +1)\n",
    "my_transformation = (vec1 * vec2) / (T.sin(vec1) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{true_div,no_inplace}.0\n"
     ]
    }
   ],
   "source": [
    "print my_transformation\n",
    "#it's okay it aint a number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compiling\n",
    "* So far we were using \"symbolic\" variables and transformations\n",
    " * Defining the recipe for computation, but not computing anything\n",
    "* To use the recipe, one should compile it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "inputs = [vec1, vec2]\n",
    "outputs = [my_transformation]\n",
    "\n",
    "# The next lines compile a function that takes two vectors and computes your transformation\n",
    "my_function = theano.function(\n",
    "    inputs, outputs,\n",
    "    allow_input_downcast=True #automatic type casting for input parameters (e.g. float64 -> float32)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using python lists:\n",
      "[array([  2.1721766 ,   5.23752832,  15.77397728], dtype=float32)]\n",
      "\n",
      "using numpy arrays:\n",
      "[array([   0.        ,    2.77555895,    5.47030783,   14.02131271,\n",
      "         89.5477066 ,  676.25805664,   47.183918  ,   24.4084301 ,\n",
      "         23.68156242,   38.24041748], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "#using function with, lists:\n",
    "print \"using python lists:\"\n",
    "print my_function([1,2,3],[4,5,6])\n",
    "print\n",
    "\n",
    "#Or using numpy arrays:\n",
    "#btw, that 'float' dtype is casted to secong parameter dtype which is float32\n",
    "print \"using numpy arrays:\"\n",
    "print my_function(np.arange(10),\n",
    "                  np.linspace(5,6,10,dtype='float'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging\n",
    "* Compilation can take a while for big functions\n",
    "* To avoid waiting, one can evaluate transformations without compiling\n",
    "* Without compilation, the code runs slower, so consider reducing input size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  2.1721766    5.23752832  15.77397728]\n",
      "add 2 vectors [ 5.  7.  9.]\n",
      "vector's shape: [3]\n"
     ]
    }
   ],
   "source": [
    "#a dictionary of inputs\n",
    "my_function_inputs = {\n",
    "    vec1:[1,2,3],\n",
    "    vec2:[4,5,6]\n",
    "}\n",
    "\n",
    "# evaluate my_transformation\n",
    "# has to match with compiled function output\n",
    "print my_transformation.eval(my_function_inputs)\n",
    "\n",
    "\n",
    "# can compute transformations on the fly\n",
    "print \"add 2 vectors\", (vec1 + vec2).eval(my_function_inputs)\n",
    "\n",
    "#!WARNING! if your transformation only depends on some inputs,\n",
    "#do not provide the rest of them\n",
    "print \"vector's shape:\", vec1.shape.eval({\n",
    "        vec1:[1,2,3]\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для отладки желательно уменьшить масштаб задачи. Если вы планировали послать на вход вектор из 10^9 примеров, пошлите 10~100.\n",
    "* Если #ОЧЕНЬ нужно послать большой вектор, быстрее скомпилировать функцию обычным способом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Теперь сам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Quest #1 - implement a function that computes a mean squared error of two input vectors\n",
    "# Your function has to take 2 vectors and return a single number\n",
    "\n",
    "vector1 = T.vector(\"v1\", dtype='float32')\n",
    "vector2 = T.vector(\"v2\", dtype='float32')\n",
    "mse_transformation = T.sum(T.power((vector1-vector2), 2))/vector1.size\n",
    "\n",
    "inputs = [vector1, vector2]\n",
    "outputs = [mse_transformation]\n",
    "\n",
    "# The next lines compile a function that takes two vectors and computes your transformation\n",
    "compute_mse = theano.function(\n",
    "    inputs, outputs,\n",
    "    allow_input_downcast=True #automatic type casting for input parameters (e.g. float64 -> float32)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "# Tests\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "for n in [1,5,10,10**3]:\n",
    "    \n",
    "    elems = [np.arange(n),np.arange(n,0,-1), np.zeros(n),\n",
    "             np.ones(n),np.random.random(n),np.random.randint(100,size=n)]\n",
    "    \n",
    "    for el in elems:\n",
    "        for el_2 in elems:\n",
    "            true_mse = np.array(mean_squared_error(el,el_2))\n",
    "            my_mse = compute_mse(el,el_2)\n",
    "            if not np.allclose(true_mse,my_mse):\n",
    "                print 'Wrong result:'\n",
    "                print 'mse(%s,%s)'%(el,el_2)\n",
    "                print \"should be: %f, but your function returned %f\"%(true_mse,my_mse)\n",
    "                raise ValueError,\"Что-то не так\"\n",
    "\n",
    "print \"All tests passed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shared variables\n",
    "\n",
    "* The inputs and transformations only exist when function is called\n",
    "\n",
    "* Shared variables always stay in memory like global variables\n",
    " * Shared variables can be included into a symbolic graph\n",
    " * They can be set and evaluated using special methods\n",
    "   * but they can't change value arbitrarily during symbolic graph computation\n",
    "   * we'll cover that later;\n",
    " \n",
    " \n",
    "* Hint: such variables are a perfect place to store network parameters\n",
    " * e.g. weights or some metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#creating shared variable\n",
    "shared_vector_1 = theano.shared(np.ones(10,dtype='float64'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial value [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "#evaluating shared variable (outside symbolicd graph)\n",
    "print \"initial value\",shared_vector_1.get_value()\n",
    "\n",
    "# within symbolic graph you use them just as any other input or transformation, not \"get value\" needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new value [ 0.  1.  2.  3.  4.]\n"
     ]
    }
   ],
   "source": [
    "#setting new value\n",
    "shared_vector_1.set_value( np.arange(5) )\n",
    "\n",
    "#getting that new value\n",
    "print \"new value\", shared_vector_1.get_value()\n",
    "\n",
    "#Note that the vector changed shape\n",
    "#This is entirely allowed... unless your graph is hard-wired to work with some fixed shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Write a recipe (transformation) that computes an elementwise transformation of shared_vector and input_scalar\n",
    "#Compile as a function of input_scalar\n",
    "\n",
    "input_scalar = T.scalar('coefficient',dtype='float32')\n",
    "\n",
    "scalar_times_shared = T.dot(input_scalar, shared_vector_1)\n",
    "\n",
    "shared_times_n = theano.function(\n",
    "    [input_scalar], [scalar_times_shared],\n",
    "    allow_input_downcast=True #automatic type casting for input parameters (e.g. float64 -> float32)\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared: [ 0.  1.  2.  3.  4.]\n",
      "shared_times_n(5) [array([  0.,   5.,  10.,  15.,  20.])]\n",
      "shared_times_n(-0.5) [array([-0. , -0.5, -1. , -1.5, -2. ])]\n"
     ]
    }
   ],
   "source": [
    "print \"shared:\", shared_vector_1.get_value()\n",
    "\n",
    "print \"shared_times_n(5)\",shared_times_n(5)\n",
    "\n",
    "print \"shared_times_n(-0.5)\",shared_times_n(-0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shared: [-1.  0.  1.]\n",
      "shared_times_n(5) [array([-5.,  0.,  5.])]\n",
      "shared_times_n(-0.5) [array([ 0.5, -0. , -0.5])]\n"
     ]
    }
   ],
   "source": [
    "#Changing value of vector 1 (output should change)\n",
    "shared_vector_1.set_value([-1,0,1])\n",
    "print \"shared:\", shared_vector_1.get_value()\n",
    "\n",
    "print \"shared_times_n(5)\",shared_times_n(5)\n",
    "\n",
    "print \"shared_times_n(-0.5)\",shared_times_n(-0.5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T.grad - why theano matters\n",
    "* Theano can compute derivatives and gradients automatically\n",
    "* Derivatives are computed symbolically, not numerically\n",
    "\n",
    "Limitations:\n",
    "* You can only compute a gradient of a __scalar__ transformation over one or several scalar or vector (or tensor) transformations or inputs.\n",
    "* A transformation has to have float32 or float64 dtype throughout the whole computation graph\n",
    " * derivative over an integer has no mathematical sense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_scalar = T.scalar(name='input',dtype='float64')\n",
    "\n",
    "scalar_squared = T.sum(my_scalar**2)\n",
    "\n",
    "#a derivative of v_squared by my_vector\n",
    "derivative = T.grad(scalar_squared,my_scalar)\n",
    "\n",
    "fun = theano.function([my_scalar],scalar_squared)\n",
    "grad = theano.function([my_scalar],derivative) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x9416e10>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAEACAYAAACqOy3+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ac8c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "x = np.linspace(-3,3)\n",
    "x_squared = map(fun,x)\n",
    "x_squared_der = map(grad,x)\n",
    "\n",
    "plt.plot(x, x_squared,label=\"x^2\")\n",
    "plt.plot(x, x_squared_der, label=\"derivative\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why that rocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "my_vector = T.vector('float64')\n",
    "\n",
    "#Compute the gradient of the next weird function over my_scalar and my_vector\n",
    "#warning! Trying to understand the meaning of that function may result in permanent brain damage\n",
    "\n",
    "weird_psychotic_function = ((my_vector+my_scalar)**(1+T.var(my_vector)) +1./T.arcsinh(my_scalar)).mean()/(my_scalar**2 +1) + 0.01*T.sin(2*my_scalar**1.5)*(T.sum(my_vector)* my_scalar**2)*T.exp((my_scalar-4)**2)/(1+T.exp((my_scalar-4)**2))*(1.-(T.exp(-(my_scalar-4)**2))/(1+T.exp(-(my_scalar-4)**2)))**2\n",
    "\n",
    "\n",
    "der_by_scalar,der_by_vector = T.grad(weird_psychotic_function, (my_scalar, my_vector))\n",
    "\n",
    "compute_weird_function = theano.function([my_scalar,my_vector],weird_psychotic_function)\n",
    "compute_der_by_scalar = theano.function([my_scalar,my_vector],der_by_scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x93b1438>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAEACAYAAACnJV25AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x79be5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plotting your derivative\n",
    "vector_0 = [1,2,3]\n",
    "\n",
    "scalar_space = np.linspace(0,7)\n",
    "\n",
    "y = [compute_weird_function(x,vector_0) for x in scalar_space]\n",
    "plt.plot(scalar_space,y,label='function')\n",
    "y_der_by_scalar = [compute_der_by_scalar(x,vector_0) for x in scalar_space]\n",
    "plt.plot(scalar_space,y_der_by_scalar,label='derivative')\n",
    "plt.grid();plt.legend()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Almost done - Updates\n",
    "\n",
    "* updates are a way of changing shared variables at after function call.\n",
    "\n",
    "* technically it's a dictionary {shared_variable : a recipe for new value} which is has to be provided when function is compiled\n",
    "\n",
    "That's how it works:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiply shared vector by a number and save the product back into shared vector\n",
    "\n",
    "inputs = [input_scalar]\n",
    "outputs = [scalar_times_shared] #return vector times scalar\n",
    "\n",
    "my_updates = {\n",
    "    shared_vector_1:scalar_times_shared #and write this same result bach into shared_vector_1\n",
    "}\n",
    "\n",
    "compute_and_save = theano.function(inputs, outputs, updates=my_updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial shared value: [ 0.  1.  2.  3.  4.]\n",
      "compute_and_save(2) returns [array([ 0.,  2.,  4.,  6.,  8.])]\n",
      "new shared value: [ 0.  2.  4.  6.  8.]\n"
     ]
    }
   ],
   "source": [
    "shared_vector_1.set_value(np.arange(5))\n",
    "\n",
    "#initial shared_vector_1\n",
    "print \"initial shared value:\" ,shared_vector_1.get_value()\n",
    "\n",
    "# evaluating the function (shared_vector_1 will be changed)\n",
    "print \"compute_and_save(2) returns\",compute_and_save(2)\n",
    "\n",
    "#evaluate new shared_vector_1\n",
    "print \"new shared value:\" ,shared_vector_1.get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic regression example\n",
    "\n",
    "Implement the regular logistic regression training algorithm\n",
    "\n",
    "Tips:\n",
    "* Weights fit in as a shared variable\n",
    "* X and y are potential inputs\n",
    "* Compile 2 functions:\n",
    " * train_function(X,y) - returns error and computes weights' new values __(through updates)__\n",
    " * predict_fun(X) - just computes probabilities (\"y\") given data\n",
    " \n",
    " \n",
    "We shall train on a two-class MNIST dataset\n",
    "* please note that target y are {0,1} and not {-1,1} as in some formulae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "mnist = load_digits(2)\n",
    "\n",
    "X,y = mnist.data, mnist.target\n",
    "\n",
    "\n",
    "print \"y [shape - %s]:\"%(str(y.shape)),y[:10]\n",
    "\n",
    "print \"X [shape - %s]:\"%(str(X.shape))\n",
    "print X[:3]\n",
    "print y[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# inputs and shareds\n",
    "shared_weights = <student.code_me()>\n",
    "input_X = <student.code_me()>\n",
    "input_y = <student.code_me()>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predicted_y = <predicted probabilities for input_X>\n",
    "loss = <logistic loss (scalar, mean over sample)>\n",
    "\n",
    "grad = <gradient of loss over model weights>\n",
    "\n",
    "\n",
    "\n",
    "updates = {\n",
    "    shared_weights: <new weights after gradient step>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_function = <compile function that takes X and y, returns log loss and updates weights>\n",
    "predict_function = <compile function that takes X and computes probabilities of y>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "for i in range(5):\n",
    "    loss_i = train_function(X_train,y_train)\n",
    "    print \"loss at iter %i:%.4f\"%(i,loss_i)\n",
    "    print \"train auc:\",roc_auc_score(y_train,predict_function(X_train))\n",
    "    print \"test auc:\",roc_auc_score(y_test,predict_function(X_test))\n",
    "\n",
    "    \n",
    "print \"resulting weights:\"\n",
    "plt.imshow(shared_weights.get_value().reshape(8,-1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lasagne\n",
    "* lasagne is a library for neural network building and training\n",
    "* it's a low-level library with almost seamless integration with theano\n",
    "\n",
    "For a demo we shall solve the same digit recognition problem, but at a different scale\n",
    "* images are now 28x28\n",
    "* 10 different digits\n",
    "* 50k samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000L, 1L, 28L, 28L) (50000L,)\n"
     ]
    }
   ],
   "source": [
    "from mnist import load_dataset\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_dataset()\n",
    "\n",
    "print X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "\n",
    "#input dimention (None means \"Arbitrary\" and only works at  the first axes [samples])\n",
    "input_shape = [None,1,28,28]\n",
    "\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Input layer (auxilary)\n",
    "input_layer = lasagne.layers.InputLayer(shape = input_shape,input_var=input_X)\n",
    "\n",
    "#fully connected layer, that takes input layer and applies 50 neurons to it.\n",
    "# nonlinearity here is sigmoid as in logistic regression\n",
    "# you can give a name to each layer (optional)\n",
    "dense_1 = lasagne.layers.DenseLayer(input_layer,num_units=50,\n",
    "                                   nonlinearity = lasagne.nonlinearities.sigmoid,\n",
    "                                   name = \"hidden_dense_layer\")\n",
    "\n",
    "#fully connected output layer that takes dense_1 as input and has 10 neurons (1 for each digit)\n",
    "#We use softmax nonlinearity to make probabilities add up to 1\n",
    "dense_output = lasagne.layers.DenseLayer(dense_1,num_units = 10,\n",
    "                                        nonlinearity = lasagne.nonlinearities.softmax,\n",
    "                                        name='output')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#network prediction (theano-transformation)\n",
    "y_predicted = lasagne.layers.get_output(dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[hidden_dense_layer.W, hidden_dense_layer.b, output.W, output.b]\n"
     ]
    }
   ],
   "source": [
    "#all network weights (shared variables)\n",
    "all_weights = lasagne.layers.get_all_params(dense_output)\n",
    "print all_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Than you could simply\n",
    "* define loss function manually\n",
    "* compute error gradient over all weights\n",
    "* define updates\n",
    "* But that's a whole lot of work and life's short\n",
    "  * not to mention life's too short to wait for SGD to converge\n",
    "\n",
    "Instead, we shall use Lasagne builtins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Mean categorical crossentropy as a loss function - similar to logistic loss but for multiclass targets\n",
    "loss = lasagne.objectives.categorical_crossentropy(y_predicted,target_y).mean()\n",
    "\n",
    "#prediction accuracy\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted,target_y).mean()\n",
    "\n",
    "#This function computes gradient AND composes weight updates just like you did earlier\n",
    "updates_sgd = lasagne.updates.sgd(loss, all_weights,learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================\n",
      "===============================\n",
      "C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: skipping incompatible C:/blaslapack/libblas.dll when searching for -lblas\r\n",
      "C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: skipping incompatible C:/blaslapack/libblas.dll when searching for -lblas\r\n",
      "C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: cannot find -lblas\r\n",
      "collect2.exe: error: ld returned 1 exit status\r\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "00001\t#include <Python.h>\n",
      "00002\t#include <iostream>\n",
      "00003\t#include \"theano_mod_helper.h\"\n",
      "00004\t#include <math.h>\n",
      "00005\t#include <numpy/arrayobject.h>\n",
      "00006\t#include <numpy/arrayscalars.h>\n",
      "00007\t#include <iostream>\n",
      "00008\t#include <time.h>\n",
      "00009\t#include <sys/time.h>\n",
      "00010\t//////////////////////\n",
      "00011\t////  Support Code\n",
      "00012\t//////////////////////\n",
      "00013\t\n",
      "00014\t\n",
      "00015\t    extern \"C\"\n",
      "00016\t    {\n",
      "00017\t\n",
      "00018\t        void xerbla_(char*, void *);\n",
      "00019\t\n",
      "00020\t    /***********/\n",
      "00021\t    /* Level 1 */\n",
      "00022\t    /***********/\n",
      "00023\t\n",
      "00024\t    /* Single Precision */\n",
      "00025\t\n",
      "00026\t        void srot_(const int*, float *, const int*, float *, const int*, const float *, const float *);\n",
      "00027\t        void srotg_(float *,float *,float *,float *);\n",
      "00028\t        void srotm_( const int*, float *, const int*, float *, const int*, const float *);\n",
      "00029\t        void srotmg_(float *,float *,float *,const float *, float *);\n",
      "00030\t        void sswap_( const int*, float *, const int*, float *, const int*);\n",
      "00031\t        void scopy_( const int*, const float *, const int*, float *, const int*);\n",
      "00032\t        void saxpy_( const int*, const float *, const float *, const int*, float *, const int*);\n",
      "00033\t        float sdot_(const int*, const float *, const int*, const float *, const int*);\n",
      "00034\t        void sdot_sub_(const int*, const float *, const int*, const float *, const int*, float *);\n",
      "00035\t        void sdsdot_sub_( const int*, const float *, const float *, const int*, const float *, const int*, float *);\n",
      "00036\t        void sscal_( const int*, const float *, float *, const int*);\n",
      "00037\t        void snrm2_sub_( const int*, const float *, const int*, float *);\n",
      "00038\t        void sasum_sub_( const int*, const float *, const int*, float *);\n",
      "00039\t        void isamax_sub_( const int*, const float * , const int*, const int*);\n",
      "00040\t\n",
      "00041\t    /* Double Precision */\n",
      "00042\t\n",
      "00043\t        void drot_(const int*, double *, const int*, double *, const int*, const double *, const double *);\n",
      "00044\t        void drotg_(double *,double *,double *,double *);\n",
      "00045\t        void drotm_( const int*, double *, const int*, double *, const int*, const double *);\n",
      "00046\t        void drotmg_(double *,double *,double *,const double *, double *);\n",
      "00047\t        void dswap_( const int*, double *, const int*, double *, const int*);\n",
      "00048\t        void dcopy_( const int*, const double *, const int*, double *, const int*);\n",
      "00049\t        void daxpy_( const int*, const double *, const double *, const int*, double *, const int*);\n",
      "00050\t        void dswap_( const int*, double *, const int*, double *, const int*);\n",
      "00051\t        double ddot_(const int*, const double *, const int*, const double *, const int*);\n",
      "00052\t        void dsdot_sub_(const int*, const float *, const int*, const float *, const int*, double *);\n",
      "00053\t        void ddot_sub_( const int*, const double *, const int*, const double *, const int*, double *);\n",
      "00054\t        void dscal_( const int*, const double *, double *, const int*);\n",
      "00055\t        void dnrm2_sub_( const int*, const double *, const int*, double *);\n",
      "00056\t        void dasum_sub_( const int*, const double *, const int*, double *);\n",
      "00057\t        void idamax_sub_( const int*, const double * , const int*, const int*);\n",
      "00058\t\n",
      "00059\t    /* Single Complex Precision */\n",
      "00060\t\n",
      "00061\t        void cswap_( const int*, void *, const int*, void *, const int*);\n",
      "00062\t        void ccopy_( const int*, const void *, const int*, void *, const int*);\n",
      "00063\t        void caxpy_( const int*, const void *, const void *, const int*, void *, const int*);\n",
      "00064\t        void cswap_( const int*, void *, const int*, void *, const int*);\n",
      "00065\t        void cdotc_sub_( const int*, const void *, const int*, const void *, const int*, void *);\n",
      "00066\t        void cdotu_sub_( const int*, const void *, const int*, const void *, const int*, void *);\n",
      "00067\t        void cscal_( const int*, const void *, void *, const int*);\n",
      "00068\t        void icamax_sub_( const int*, const void *, const int*, const int*);\n",
      "00069\t        void csscal_( const int*, const float *, void *, const int*);\n",
      "00070\t        void scnrm2_sub_( const int*, const void *, const int*, float *);\n",
      "00071\t        void scasum_sub_( const int*, const void *, const int*, float *);\n",
      "00072\t\n",
      "00073\t    /* Double Complex Precision */\n",
      "00074\t\n",
      "00075\t        void zswap_( const int*, void *, const int*, void *, const int*);\n",
      "00076\t        void zcopy_( const int*, const void *, const int*, void *, const int*);\n",
      "00077\t        void zaxpy_( const int*, const void *, const void *, const int*, void *, const int*);\n",
      "00078\t        void zswap_( const int*, void *, const int*, void *, const int*);\n",
      "00079\t        void zdotc_sub_( const int*, const void *, const int*, const void *, const int*, void *);\n",
      "00080\t        void zdotu_sub_( const int*, const void *, const int*, const void *, const int*, void *);\n",
      "00081\t        void zdscal_( const int*, const double *, void *, const int*);\n",
      "00082\t        void zscal_( const int*, const void *, void *, const int*);\n",
      "00083\t        void dznrm2_sub_( const int*, const void *, const int*, double *);\n",
      "00084\t        void dzasum_sub_( const int*, const void *, const int*, double *);\n",
      "00085\t        void izamax_sub_( const int*, const void *, const int*, const int*);\n",
      "00086\t\n",
      "00087\t    /***********/\n",
      "00088\t    /* Level 2 */\n",
      "00089\t    /***********/\n",
      "00090\t\n",
      "00091\t    /* Single Precision */\n",
      "00092\t\n",
      "00093\t        void sgemv_(char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00094\t        void sgbmv_(char*, const int*, const int*, const int*, const int*, const float *,  const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00095\t        void ssymv_(char*, const int*, const float *, const float *, const int*, const float *,  const int*, const float *, float *, const int*);\n",
      "00096\t        void ssbmv_(char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00097\t        void sspmv_(char*, const int*, const float *, const float *, const float *, const int*, const float *, float *, const int*);\n",
      "00098\t        void strmv_( char*, char*, char*, const int*, const float *, const int*, float *, const int*);\n",
      "00099\t        void stbmv_( char*, char*, char*, const int*, const int*, const float *, const int*, float *, const int*);\n",
      "00100\t        void strsv_( char*, char*, char*, const int*, const float *, const int*, float *, const int*);\n",
      "00101\t        void stbsv_( char*, char*, char*, const int*, const int*, const float *, const int*, float *, const int*);\n",
      "00102\t        void stpmv_( char*, char*, char*, const int*, const float *, float *, const int*);\n",
      "00103\t        void stpsv_( char*, char*, char*, const int*, const float *, float *, const int*);\n",
      "00104\t        void sger_( const int*, const int*, const float *, const float *, const int*, const float *, const int*, float *, const int*);\n",
      "00105\t        void ssyr_(char*, const int*, const float *, const float *, const int*, float *, const int*);\n",
      "00106\t        void sspr_(char*, const int*, const float *, const float *, const int*, float *);\n",
      "00107\t        void sspr2_(char*, const int*, const float *, const float *, const int*, const float *, const int*,  float *);\n",
      "00108\t        void ssyr2_(char*, const int*, const float *, const float *, const int*, const float *, const int*,  float *, const int*);\n",
      "00109\t\n",
      "00110\t    /* Double Precision */\n",
      "00111\t\n",
      "00112\t        void dgemv_(char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00113\t        void dgbmv_(char*, const int*, const int*, const int*, const int*, const double *,  const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00114\t        void dsymv_(char*, const int*, const double *, const double *, const int*, const double *,  const int*, const double *, double *, const int*);\n",
      "00115\t        void dsbmv_(char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00116\t        void dspmv_(char*, const int*, const double *, const double *, const double *, const int*, const double *, double *, const int*);\n",
      "00117\t        void dtrmv_( char*, char*, char*, const int*, const double *, const int*, double *, const int*);\n",
      "00118\t        void dtbmv_( char*, char*, char*, const int*, const int*, const double *, const int*, double *, const int*);\n",
      "00119\t        void dtrsv_( char*, char*, char*, const int*, const double *, const int*, double *, const int*);\n",
      "00120\t        void dtbsv_( char*, char*, char*, const int*, const int*, const double *, const int*, double *, const int*);\n",
      "00121\t        void dtpmv_( char*, char*, char*, const int*, const double *, double *, const int*);\n",
      "00122\t        void dtpsv_( char*, char*, char*, const int*, const double *, double *, const int*);\n",
      "00123\t        void dger_( const int*, const int*, const double *, const double *, const int*, const double *, const int*, double *, const int*);\n",
      "00124\t        void dsyr_(char*, const int*, const double *, const double *, const int*, double *, const int*);\n",
      "00125\t        void dspr_(char*, const int*, const double *, const double *, const int*, double *);\n",
      "00126\t        void dspr2_(char*, const int*, const double *, const double *, const int*, const double *, const int*,  double *);\n",
      "00127\t        void dsyr2_(char*, const int*, const double *, const double *, const int*, const double *, const int*,  double *, const int*);\n",
      "00128\t\n",
      "00129\t    /* Single Complex Precision */\n",
      "00130\t\n",
      "00131\t        void cgemv_(char*, const int*, const int*, const void *, const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00132\t        void cgbmv_(char*, const int*, const int*, const int*, const int*, const void *,  const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00133\t        void chemv_(char*, const int*, const void *, const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00134\t        void chbmv_(char*, const int*, const int*, const void *, const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00135\t        void chpmv_(char*, const int*, const void *, const void *, const void *, const int*, const void *, void *, const int*);\n",
      "00136\t        void ctrmv_( char*, char*, char*, const int*, const void *, const int*, void *, const int*);\n",
      "00137\t        void ctbmv_( char*, char*, char*, const int*, const int*, const void *, const int*, void *, const int*);\n",
      "00138\t        void ctpmv_( char*, char*, char*, const int*, const void *, void *, const int*);\n",
      "00139\t        void ctrsv_( char*, char*, char*, const int*, const void *, const int*, void *, const int*);\n",
      "00140\t        void ctbsv_( char*, char*, char*, const int*, const int*, const void *, const int*, void *, const int*);\n",
      "00141\t        void ctpsv_( char*, char*, char*, const int*, const void *, void *,const int*);\n",
      "00142\t        void cgerc_( const int*, const int*, const void *, const void *, const int*, const void *, const int*, void *, const int*);\n",
      "00143\t        void cgeru_( const int*, const int*, const void *, const void *, const int*, const void *, const int*, void *,  const int*);\n",
      "00144\t        void cher_(char*, const int*, const float *, const void *, const int*, void *, const int*);\n",
      "00145\t        void cher2_(char*, const int*, const void *, const void *, const int*, const void *, const int*, void *, const int*);\n",
      "00146\t        void chpr_(char*, const int*, const float *, const void *, const int*, void *);\n",
      "00147\t        void chpr2_(char*, const int*, const float *, const void *, const int*, const void *, const int*, void *);\n",
      "00148\t\n",
      "00149\t    /* Double Complex Precision */\n",
      "00150\t\n",
      "00151\t        void zgemv_(char*, const int*, const int*, const void *, const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00152\t        void zgbmv_(char*, const int*, const int*, const int*, const int*, const void *,  const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00153\t        void zhemv_(char*, const int*, const void *, const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00154\t        void zhbmv_(char*, const int*, const int*, const void *, const void *, const int*, const void *, const int*, const void *, void *, const int*);\n",
      "00155\t        void zhpmv_(char*, const int*, const void *, const void *, const void *, const int*, const void *, void *, const int*);\n",
      "00156\t        void ztrmv_( char*, char*, char*, const int*, const void *, const int*, void *, const int*);\n",
      "00157\t        void ztbmv_( char*, char*, char*, const int*, const int*, const void *, const int*, void *, const int*);\n",
      "00158\t        void ztpmv_( char*, char*, char*, const int*, const void *, void *, const int*);\n",
      "00159\t        void ztrsv_( char*, char*, char*, const int*, const void *, const int*, void *, const int*);\n",
      "00160\t        void ztbsv_( char*, char*, char*, const int*, const int*, const void *, const int*, void *, const int*);\n",
      "00161\t        void ztpsv_( char*, char*, char*, const int*, const void *, void *,const int*);\n",
      "00162\t        void zgerc_( const int*, const int*, const void *, const void *, const int*, const void *, const int*, void *, const int*);\n",
      "00163\t        void zgeru_( const int*, const int*, const void *, const void *, const int*, const void *, const int*, void *,  const int*);\n",
      "00164\t        void zher_(char*, const int*, const double *, const void *, const int*, void *, const int*);\n",
      "00165\t        void zher2_(char*, const int*, const void *, const void *, const int*, const void *, const int*, void *, const int*);\n",
      "00166\t        void zhpr_(char*, const int*, const double *, const void *, const int*, void *);\n",
      "00167\t        void zhpr2_(char*, const int*, const double *, const void *, const int*, const void *, const int*, void *);\n",
      "00168\t\n",
      "00169\t    /***********/\n",
      "00170\t    /* Level 3 */\n",
      "00171\t    /***********/\n",
      "00172\t\n",
      "00173\t    /* Single Precision */\n",
      "00174\t\n",
      "00175\t        void sgemm_(char*, char*, const int*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00176\t        void ssymm_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00177\t        void ssyrk_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, float *, const int*);\n",
      "00178\t        void ssyr2k_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00179\t        void strmm_(char*, char*, char*, char*, const int*, const int*, const float *, const float *, const int*, float *, const int*);\n",
      "00180\t        void strsm_(char*, char*, char*, char*, const int*, const int*, const float *, const float *, const int*, float *, const int*);\n",
      "00181\t\n",
      "00182\t    /* Double Precision */\n",
      "00183\t\n",
      "00184\t        void dgemm_(char*, char*, const int*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00185\t        void dsymm_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00186\t        void dsyrk_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, double *, const int*);\n",
      "00187\t        void dsyr2k_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00188\t        void dtrmm_(char*, char*, char*, char*, const int*, const int*, const double *, const double *, const int*, double *, const int*);\n",
      "00189\t        void dtrsm_(char*, char*, char*, char*, const int*, const int*, const double *, const double *, const int*, double *, const int*);\n",
      "00190\t\n",
      "00191\t    /* Single Complex Precision */\n",
      "00192\t\n",
      "00193\t        void cgemm_(char*, char*, const int*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00194\t        void csymm_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00195\t        void chemm_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00196\t        void csyrk_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, float *, const int*);\n",
      "00197\t        void cherk_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, float *, const int*);\n",
      "00198\t        void csyr2k_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00199\t        void cher2k_(char*, char*, const int*, const int*, const float *, const float *, const int*, const float *, const int*, const float *, float *, const int*);\n",
      "00200\t        void ctrmm_(char*, char*, char*, char*, const int*, const int*, const float *, const float *, const int*, float *, const int*);\n",
      "00201\t        void ctrsm_(char*, char*, char*, char*, const int*, const int*, const float *, const float *, const int*, float *, const int*);\n",
      "00202\t\n",
      "00203\t    /* Double Complex Precision */\n",
      "00204\t\n",
      "00205\t        void zgemm_(char*, char*, const int*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00206\t        void zsymm_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00207\t        void zhemm_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00208\t        void zsyrk_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, double *, const int*);\n",
      "00209\t        void zherk_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, double *, const int*);\n",
      "00210\t        void zsyr2k_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00211\t        void zher2k_(char*, char*, const int*, const int*, const double *, const double *, const int*, const double *, const int*, const double *, double *, const int*);\n",
      "00212\t        void ztrmm_(char*, char*, char*, char*, const int*, const int*, const double *, const double *, const int*, double *, const int*);\n",
      "00213\t        void ztrsm_(char*, char*, char*, char*, const int*, const int*, const double *, const double *, const int*, double *, const int*);\n",
      "00214\t\n",
      "00215\t    }\n",
      "00216\t    \n",
      "00217\t        #ifndef MOD\n",
      "00218\t        #define MOD %\n",
      "00219\t        #endif\n",
      "00220\t        static double time_time() // a time function like time.time()\n",
      "00221\t        {\n",
      "00222\t            struct timeval tv;\n",
      "00223\t            gettimeofday(&tv, 0);\n",
      "00224\t            return (double) tv.tv_sec + (double) tv.tv_usec / 1000000.0;\n",
      "00225\t        }\n",
      "00226\t        \n",
      "00227\t\n",
      "00228\t    namespace {\n",
      "00229\t    struct __struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd {\n",
      "00230\t        PyObject* __ERROR;\n",
      "00231\t\n",
      "00232\t        PyObject* storage_V3;\n",
      "00233\tPyObject* storage_V5;\n",
      "00234\tPyObject* storage_V1;\n",
      "00235\t        \n",
      "00236\t\n",
      "00237\t        __struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd() {\n",
      "00238\t            // This is only somewhat safe because we:\n",
      "00239\t            //  1) Are not a virtual class\n",
      "00240\t            //  2) Do not use any virtual classes in the members\n",
      "00241\t            //  3) Deal with mostly POD and pointers\n",
      "00242\t\n",
      "00243\t            // If this changes, we would have to revise this, but for\n",
      "00244\t            // now I am tired of chasing segfaults because\n",
      "00245\t            // initialization code had an error and some pointer has\n",
      "00246\t            // a junk value.\n",
      "00247\t            memset(this, 0, sizeof(*this));\n",
      "00248\t        }\n",
      "00249\t        ~__struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd(void) {\n",
      "00250\t            cleanup();\n",
      "00251\t        }\n",
      "00252\t\n",
      "00253\t        int init(PyObject* __ERROR, PyObject* storage_V3, PyObject* storage_V5, PyObject* storage_V1) {\n",
      "00254\t            Py_XINCREF(storage_V3);\n",
      "00255\tPy_XINCREF(storage_V5);\n",
      "00256\tPy_XINCREF(storage_V1);\n",
      "00257\t            this->storage_V3 = storage_V3;\n",
      "00258\tthis->storage_V5 = storage_V5;\n",
      "00259\tthis->storage_V1 = storage_V1;\n",
      "00260\t            \n",
      "00261\t\n",
      "00262\t\n",
      "00263\t\n",
      "00264\t\n",
      "00265\t            this->__ERROR = __ERROR;\n",
      "00266\t            return 0;\n",
      "00267\t        }\n",
      "00268\t        void cleanup(void) {\n",
      "00269\t            __label_1:\n",
      "00270\t\n",
      "00271\tdouble __DUMMY_1;\n",
      "00272\t__label_3:\n",
      "00273\t\n",
      "00274\tdouble __DUMMY_3;\n",
      "00275\t__label_5:\n",
      "00276\t\n",
      "00277\tdouble __DUMMY_5;\n",
      "00278\t__label_8:\n",
      "00279\t\n",
      "00280\tdouble __DUMMY_8;\n",
      "00281\t\n",
      "00282\t            Py_XDECREF(this->storage_V3);\n",
      "00283\tPy_XDECREF(this->storage_V5);\n",
      "00284\tPy_XDECREF(this->storage_V1);\n",
      "00285\t        }\n",
      "00286\t        int run(void) {\n",
      "00287\t            int __failure = 0;\n",
      "00288\t            \n",
      "00289\t    PyObject* py_V1;\n",
      "00290\t    \n",
      "00291\t        PyArrayObject* V1;\n",
      "00292\t        \n",
      "00293\t            typedef npy_float32 dtype_V1;\n",
      "00294\t            \n",
      "00295\t    PyObject* py_V3;\n",
      "00296\t    \n",
      "00297\t        PyArrayObject* V3;\n",
      "00298\t        \n",
      "00299\t            typedef npy_float32 dtype_V3;\n",
      "00300\t            \n",
      "00301\t    PyObject* py_V5;\n",
      "00302\t    \n",
      "00303\t        PyArrayObject* V5;\n",
      "00304\t        \n",
      "00305\t            typedef npy_float32 dtype_V5;\n",
      "00306\t            \n",
      "00307\t{\n",
      "00308\t\n",
      "00309\t    py_V1 = PyList_GET_ITEM(storage_V1, 0);\n",
      "00310\t    {Py_XINCREF(py_V1);}\n",
      "00311\t    \n",
      "00312\t        if (py_V1 == Py_None)\n",
      "00313\t        {\n",
      "00314\t            \n",
      "00315\t        V1 = NULL;\n",
      "00316\t        \n",
      "00317\t        }\n",
      "00318\t        else\n",
      "00319\t        {\n",
      "00320\t            \n",
      "00321\t            V1 = NULL;\n",
      "00322\t            if (py_V1 == Py_None) {\n",
      "00323\t                // We can either fail here or set V1 to NULL and rely on Ops\n",
      "00324\t                // using tensors to handle the NULL case, but if they fail to do so\n",
      "00325\t                // they'll end up with nasty segfaults, so this is public service.\n",
      "00326\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray, not None\");\n",
      "00327\t                {\n",
      "00328\t        __failure = 2;\n",
      "00329\t        if (!PyErr_Occurred()) {\n",
      "00330\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00331\t                \"Unexpected error in an Op's C code. \"\n",
      "00332\t                \"No Python exception was set.\");\n",
      "00333\t            }\n",
      "00334\t        goto __label_2;}\n",
      "00335\t            }\n",
      "00336\t            if (!PyArray_Check(py_V1)) {\n",
      "00337\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray\");\n",
      "00338\t                {\n",
      "00339\t        __failure = 2;\n",
      "00340\t        if (!PyErr_Occurred()) {\n",
      "00341\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00342\t                \"Unexpected error in an Op's C code. \"\n",
      "00343\t                \"No Python exception was set.\");\n",
      "00344\t            }\n",
      "00345\t        goto __label_2;}\n",
      "00346\t            }\n",
      "00347\t            // We expect NPY_FLOAT32\n",
      "00348\t            if (!PyArray_ISALIGNED((PyArrayObject*) py_V1)) {\n",
      "00349\t                PyArrayObject * tmp = (PyArrayObject*) py_V1;\n",
      "00350\t                PyErr_Format(PyExc_NotImplementedError,\n",
      "00351\t                             \"expected an aligned array of type %ld \"\n",
      "00352\t                             \"(NPY_FLOAT32), got non-aligned array of type %ld\"\n",
      "00353\t                             \" with %ld dimensions, with 3 last dims \"\n",
      "00354\t                             \"%ld, %ld, %ld\"\n",
      "00355\t                             \" and 3 last strides %ld %ld, %ld.\",\n",
      "00356\t                             (long int) NPY_FLOAT32,\n",
      "00357\t                             (long int) PyArray_TYPE((PyArrayObject*) py_V1),\n",
      "00358\t                             (long int) PyArray_NDIM(tmp),\n",
      "00359\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00360\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00361\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00362\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00363\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00364\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-1] : -1,\n",
      "00365\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00366\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00367\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00368\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00369\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00370\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-1] : -1\n",
      "00371\t            );\n",
      "00372\t                {\n",
      "00373\t        __failure = 2;\n",
      "00374\t        if (!PyErr_Occurred()) {\n",
      "00375\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00376\t                \"Unexpected error in an Op's C code. \"\n",
      "00377\t                \"No Python exception was set.\");\n",
      "00378\t            }\n",
      "00379\t        goto __label_2;}\n",
      "00380\t            }\n",
      "00381\t            // This is a TypeError to be consistent with DEBUG_MODE\n",
      "00382\t            // Note: DEBUG_MODE also tells the name of the container\n",
      "00383\t            if (PyArray_TYPE((PyArrayObject*) py_V1) != NPY_FLOAT32) {\n",
      "00384\t                PyErr_Format(PyExc_TypeError,\n",
      "00385\t                             \"expected type_num %d (NPY_FLOAT32) got %d\",\n",
      "00386\t                             NPY_FLOAT32, PyArray_TYPE((PyArrayObject*) py_V1));\n",
      "00387\t                {\n",
      "00388\t        __failure = 2;\n",
      "00389\t        if (!PyErr_Occurred()) {\n",
      "00390\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00391\t                \"Unexpected error in an Op's C code. \"\n",
      "00392\t                \"No Python exception was set.\");\n",
      "00393\t            }\n",
      "00394\t        goto __label_2;}\n",
      "00395\t            }\n",
      "00396\t            \n",
      "00397\t        V1 = (PyArrayObject*)(py_V1);\n",
      "00398\t        Py_XINCREF(V1);\n",
      "00399\t        \n",
      "00400\t        }\n",
      "00401\t        \n",
      "00402\t{\n",
      "00403\t\n",
      "00404\t    py_V3 = PyList_GET_ITEM(storage_V3, 0);\n",
      "00405\t    {Py_XINCREF(py_V3);}\n",
      "00406\t    \n",
      "00407\t            V3 = NULL;\n",
      "00408\t            if (py_V3 == Py_None) {\n",
      "00409\t                // We can either fail here or set V3 to NULL and rely on Ops\n",
      "00410\t                // using tensors to handle the NULL case, but if they fail to do so\n",
      "00411\t                // they'll end up with nasty segfaults, so this is public service.\n",
      "00412\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray, not None\");\n",
      "00413\t                {\n",
      "00414\t        __failure = 4;\n",
      "00415\t        if (!PyErr_Occurred()) {\n",
      "00416\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00417\t                \"Unexpected error in an Op's C code. \"\n",
      "00418\t                \"No Python exception was set.\");\n",
      "00419\t            }\n",
      "00420\t        goto __label_4;}\n",
      "00421\t            }\n",
      "00422\t            if (!PyArray_Check(py_V3)) {\n",
      "00423\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray\");\n",
      "00424\t                {\n",
      "00425\t        __failure = 4;\n",
      "00426\t        if (!PyErr_Occurred()) {\n",
      "00427\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00428\t                \"Unexpected error in an Op's C code. \"\n",
      "00429\t                \"No Python exception was set.\");\n",
      "00430\t            }\n",
      "00431\t        goto __label_4;}\n",
      "00432\t            }\n",
      "00433\t            // We expect NPY_FLOAT32\n",
      "00434\t            if (!PyArray_ISALIGNED((PyArrayObject*) py_V3)) {\n",
      "00435\t                PyArrayObject * tmp = (PyArrayObject*) py_V3;\n",
      "00436\t                PyErr_Format(PyExc_NotImplementedError,\n",
      "00437\t                             \"expected an aligned array of type %ld \"\n",
      "00438\t                             \"(NPY_FLOAT32), got non-aligned array of type %ld\"\n",
      "00439\t                             \" with %ld dimensions, with 3 last dims \"\n",
      "00440\t                             \"%ld, %ld, %ld\"\n",
      "00441\t                             \" and 3 last strides %ld %ld, %ld.\",\n",
      "00442\t                             (long int) NPY_FLOAT32,\n",
      "00443\t                             (long int) PyArray_TYPE((PyArrayObject*) py_V3),\n",
      "00444\t                             (long int) PyArray_NDIM(tmp),\n",
      "00445\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00446\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00447\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00448\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00449\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00450\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-1] : -1,\n",
      "00451\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00452\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00453\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00454\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00455\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00456\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-1] : -1\n",
      "00457\t            );\n",
      "00458\t                {\n",
      "00459\t        __failure = 4;\n",
      "00460\t        if (!PyErr_Occurred()) {\n",
      "00461\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00462\t                \"Unexpected error in an Op's C code. \"\n",
      "00463\t                \"No Python exception was set.\");\n",
      "00464\t            }\n",
      "00465\t        goto __label_4;}\n",
      "00466\t            }\n",
      "00467\t            // This is a TypeError to be consistent with DEBUG_MODE\n",
      "00468\t            // Note: DEBUG_MODE also tells the name of the container\n",
      "00469\t            if (PyArray_TYPE((PyArrayObject*) py_V3) != NPY_FLOAT32) {\n",
      "00470\t                PyErr_Format(PyExc_TypeError,\n",
      "00471\t                             \"expected type_num %d (NPY_FLOAT32) got %d\",\n",
      "00472\t                             NPY_FLOAT32, PyArray_TYPE((PyArrayObject*) py_V3));\n",
      "00473\t                {\n",
      "00474\t        __failure = 4;\n",
      "00475\t        if (!PyErr_Occurred()) {\n",
      "00476\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00477\t                \"Unexpected error in an Op's C code. \"\n",
      "00478\t                \"No Python exception was set.\");\n",
      "00479\t            }\n",
      "00480\t        goto __label_4;}\n",
      "00481\t            }\n",
      "00482\t            \n",
      "00483\t        V3 = (PyArrayObject*)(py_V3);\n",
      "00484\t        Py_XINCREF(V3);\n",
      "00485\t        \n",
      "00486\t{\n",
      "00487\t\n",
      "00488\t    py_V5 = PyList_GET_ITEM(storage_V5, 0);\n",
      "00489\t    {Py_XINCREF(py_V5);}\n",
      "00490\t    \n",
      "00491\t            V5 = NULL;\n",
      "00492\t            if (py_V5 == Py_None) {\n",
      "00493\t                // We can either fail here or set V5 to NULL and rely on Ops\n",
      "00494\t                // using tensors to handle the NULL case, but if they fail to do so\n",
      "00495\t                // they'll end up with nasty segfaults, so this is public service.\n",
      "00496\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray, not None\");\n",
      "00497\t                {\n",
      "00498\t        __failure = 6;\n",
      "00499\t        if (!PyErr_Occurred()) {\n",
      "00500\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00501\t                \"Unexpected error in an Op's C code. \"\n",
      "00502\t                \"No Python exception was set.\");\n",
      "00503\t            }\n",
      "00504\t        goto __label_6;}\n",
      "00505\t            }\n",
      "00506\t            if (!PyArray_Check(py_V5)) {\n",
      "00507\t                PyErr_SetString(PyExc_ValueError, \"expected an ndarray\");\n",
      "00508\t                {\n",
      "00509\t        __failure = 6;\n",
      "00510\t        if (!PyErr_Occurred()) {\n",
      "00511\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00512\t                \"Unexpected error in an Op's C code. \"\n",
      "00513\t                \"No Python exception was set.\");\n",
      "00514\t            }\n",
      "00515\t        goto __label_6;}\n",
      "00516\t            }\n",
      "00517\t            // We expect NPY_FLOAT32\n",
      "00518\t            if (!PyArray_ISALIGNED((PyArrayObject*) py_V5)) {\n",
      "00519\t                PyArrayObject * tmp = (PyArrayObject*) py_V5;\n",
      "00520\t                PyErr_Format(PyExc_NotImplementedError,\n",
      "00521\t                             \"expected an aligned array of type %ld \"\n",
      "00522\t                             \"(NPY_FLOAT32), got non-aligned array of type %ld\"\n",
      "00523\t                             \" with %ld dimensions, with 3 last dims \"\n",
      "00524\t                             \"%ld, %ld, %ld\"\n",
      "00525\t                             \" and 3 last strides %ld %ld, %ld.\",\n",
      "00526\t                             (long int) NPY_FLOAT32,\n",
      "00527\t                             (long int) PyArray_TYPE((PyArrayObject*) py_V5),\n",
      "00528\t                             (long int) PyArray_NDIM(tmp),\n",
      "00529\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00530\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00531\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00532\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00533\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00534\t            PyArray_DIMS(tmp)[PyArray_NDIM(tmp)-1] : -1,\n",
      "00535\t                             (long int) PyArray_NDIM(tmp) >= 3 ?\n",
      "00536\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-3] : -1,\n",
      "00537\t                             (long int) PyArray_NDIM(tmp) >= 2 ?\n",
      "00538\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-2] : -1,\n",
      "00539\t                             (long int) PyArray_NDIM(tmp) >= 1 ?\n",
      "00540\t            PyArray_STRIDES(tmp)[PyArray_NDIM(tmp)-1] : -1\n",
      "00541\t            );\n",
      "00542\t                {\n",
      "00543\t        __failure = 6;\n",
      "00544\t        if (!PyErr_Occurred()) {\n",
      "00545\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00546\t                \"Unexpected error in an Op's C code. \"\n",
      "00547\t                \"No Python exception was set.\");\n",
      "00548\t            }\n",
      "00549\t        goto __label_6;}\n",
      "00550\t            }\n",
      "00551\t            // This is a TypeError to be consistent with DEBUG_MODE\n",
      "00552\t            // Note: DEBUG_MODE also tells the name of the container\n",
      "00553\t            if (PyArray_TYPE((PyArrayObject*) py_V5) != NPY_FLOAT32) {\n",
      "00554\t                PyErr_Format(PyExc_TypeError,\n",
      "00555\t                             \"expected type_num %d (NPY_FLOAT32) got %d\",\n",
      "00556\t                             NPY_FLOAT32, PyArray_TYPE((PyArrayObject*) py_V5));\n",
      "00557\t                {\n",
      "00558\t        __failure = 6;\n",
      "00559\t        if (!PyErr_Occurred()) {\n",
      "00560\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00561\t                \"Unexpected error in an Op's C code. \"\n",
      "00562\t                \"No Python exception was set.\");\n",
      "00563\t            }\n",
      "00564\t        goto __label_6;}\n",
      "00565\t            }\n",
      "00566\t            \n",
      "00567\t        V5 = (PyArrayObject*)(py_V5);\n",
      "00568\t        Py_XINCREF(V5);\n",
      "00569\t        \n",
      "00570\t{\n",
      "00571\t// Op class Dot22\n",
      "00572\t\n",
      "00573\t        int unit = 0;\n",
      "00574\t\n",
      "00575\t        int type_num = PyArray_DESCR(V3)->type_num;\n",
      "00576\t        int type_size = PyArray_DESCR(V3)->elsize; // in bytes\n",
      "00577\t\n",
      "00578\t        npy_intp* Nx = PyArray_DIMS(V3);\n",
      "00579\t        npy_intp* Ny = PyArray_DIMS(V5);\n",
      "00580\t        npy_intp* Nz = 0; //PyArray_DIMS(V1);\n",
      "00581\t\n",
      "00582\t        npy_intp* Sx = PyArray_STRIDES(V3);\n",
      "00583\t        npy_intp* Sy = PyArray_STRIDES(V5);\n",
      "00584\t        npy_intp* Sz = 0; //PyArray_STRIDES(V1);\n",
      "00585\t\n",
      "00586\t        //strides for x, y, z in dimensions 0, 1\n",
      "00587\t        int sx_0, sx_1, sy_0, sy_1, sz_0, sz_1;\n",
      "00588\t        \n",
      "00589\t        if (PyArray_NDIM(V3) != 2) {\n",
      "00590\t            PyErr_Format(PyExc_NotImplementedError,\n",
      "00591\t                         \"rank(x) != 2. rank(x) is %d.\",\n",
      "00592\t                         PyArray_NDIM(V3));\n",
      "00593\t            {\n",
      "00594\t        __failure = 7;\n",
      "00595\t        if (!PyErr_Occurred()) {\n",
      "00596\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00597\t                \"Unexpected error in an Op's C code. \"\n",
      "00598\t                \"No Python exception was set.\");\n",
      "00599\t            }\n",
      "00600\t        goto __label_7;};\n",
      "00601\t        }\n",
      "00602\t        if (PyArray_NDIM(V5) != 2) {\n",
      "00603\t            PyErr_Format(PyExc_NotImplementedError,\n",
      "00604\t                         \"rank(y) != 2. rank(y) is %d.\", PyArray_NDIM(V5));\n",
      "00605\t            {\n",
      "00606\t        __failure = 7;\n",
      "00607\t        if (!PyErr_Occurred()) {\n",
      "00608\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00609\t                \"Unexpected error in an Op's C code. \"\n",
      "00610\t                \"No Python exception was set.\");\n",
      "00611\t            }\n",
      "00612\t        goto __label_7;};\n",
      "00613\t        }\n",
      "00614\t        if (V1 && PyArray_NDIM(V1) != 2) {\n",
      "00615\t            PyErr_Format(PyExc_NotImplementedError,\n",
      "00616\t                         \"rank(z) != 2. rank(z) is %d.\", PyArray_NDIM(V1));\n",
      "00617\t            {\n",
      "00618\t        __failure = 7;\n",
      "00619\t        if (!PyErr_Occurred()) {\n",
      "00620\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00621\t                \"Unexpected error in an Op's C code. \"\n",
      "00622\t                \"No Python exception was set.\");\n",
      "00623\t            }\n",
      "00624\t        goto __label_7;};\n",
      "00625\t        }\n",
      "00626\t        \n",
      "00627\t        if ((NULL == V1)\n",
      "00628\t            || (PyArray_DIMS(V1)[0] != PyArray_DIMS(V3)[0])\n",
      "00629\t            || (PyArray_DIMS(V1)[1] != PyArray_DIMS(V5)[1]))\n",
      "00630\t        {\n",
      "00631\t            if (NULL != V1) Py_XDECREF(V1);\n",
      "00632\t            npy_intp dims[2];\n",
      "00633\t            dims[0] = PyArray_DIMS(V3)[0];\n",
      "00634\t            dims[1] = PyArray_DIMS(V5)[1];\n",
      "00635\t            V1 = (PyArrayObject*)PyArray_SimpleNew(2, dims,\n",
      "00636\t                            PyArray_TYPE(V3));\n",
      "00637\t            //fprintf(stderr, \"Dot Allocating %i %i\\n\", dims[0], dims[1]);\n",
      "00638\t            if(!V1) {\n",
      "00639\t                PyErr_SetString(PyExc_MemoryError,\n",
      "00640\t                                \"failed to alloc dot22 output\");\n",
      "00641\t                {\n",
      "00642\t        __failure = 7;\n",
      "00643\t        if (!PyErr_Occurred()) {\n",
      "00644\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00645\t                \"Unexpected error in an Op's C code. \"\n",
      "00646\t                \"No Python exception was set.\");\n",
      "00647\t            }\n",
      "00648\t        goto __label_7;}\n",
      "00649\t            }\n",
      "00650\t        }\n",
      "00651\t        Nz = PyArray_DIMS(V1);\n",
      "00652\t        Sz = PyArray_STRIDES(V1);\n",
      "00653\t\n",
      "00654\t        \n",
      "00655\t        if ((PyArray_DESCR(V3)->type_num != NPY_DOUBLE)\n",
      "00656\t            && (PyArray_DESCR(V3)->type_num != NPY_FLOAT))\n",
      "00657\t        {PyErr_SetString(PyExc_NotImplementedError, \"type(x) is not double or float\"); {\n",
      "00658\t        __failure = 7;\n",
      "00659\t        if (!PyErr_Occurred()) {\n",
      "00660\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00661\t                \"Unexpected error in an Op's C code. \"\n",
      "00662\t                \"No Python exception was set.\");\n",
      "00663\t            }\n",
      "00664\t        goto __label_7;};}\n",
      "00665\t\n",
      "00666\t        if ((PyArray_DESCR(V5)->type_num != NPY_DOUBLE)\n",
      "00667\t            && (PyArray_DESCR(V5)->type_num != NPY_FLOAT))\n",
      "00668\t        {PyErr_SetString(PyExc_NotImplementedError, \"type(y) is not double or float\"); {\n",
      "00669\t        __failure = 7;\n",
      "00670\t        if (!PyErr_Occurred()) {\n",
      "00671\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00672\t                \"Unexpected error in an Op's C code. \"\n",
      "00673\t                \"No Python exception was set.\");\n",
      "00674\t            }\n",
      "00675\t        goto __label_7;};}\n",
      "00676\t\n",
      "00677\t        if ((PyArray_DESCR(V1)->type_num != NPY_DOUBLE)\n",
      "00678\t            && (PyArray_DESCR(V1)->type_num != NPY_FLOAT))\n",
      "00679\t        {PyErr_SetString(PyExc_NotImplementedError, \"type(z) is not double or float\"); {\n",
      "00680\t        __failure = 7;\n",
      "00681\t        if (!PyErr_Occurred()) {\n",
      "00682\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00683\t                \"Unexpected error in an Op's C code. \"\n",
      "00684\t                \"No Python exception was set.\");\n",
      "00685\t            }\n",
      "00686\t        goto __label_7;};}\n",
      "00687\t\n",
      "00688\t        if ((PyArray_DESCR(V3)->type_num != PyArray_DESCR(V5)->type_num)\n",
      "00689\t            ||(PyArray_DESCR(V3)->type_num != PyArray_DESCR(V1)->type_num))\n",
      "00690\t        { PyErr_SetString(PyExc_NotImplementedError, \"type(x), type(y), type(z) are not all the same\"); {\n",
      "00691\t        __failure = 7;\n",
      "00692\t        if (!PyErr_Occurred()) {\n",
      "00693\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00694\t                \"Unexpected error in an Op's C code. \"\n",
      "00695\t                \"No Python exception was set.\");\n",
      "00696\t            }\n",
      "00697\t        goto __label_7;}; }\n",
      "00698\t        \n",
      "00699\t        if (Nx[0] != Nz[0])\n",
      "00700\t        {\n",
      "00701\t            PyErr_Format(PyExc_ValueError,\n",
      "00702\t                \"Shape mismatch: x has %ld rows but z has %ld rows\",\n",
      "00703\t                (long int)Nx[0], (long int)Nz[0]);\n",
      "00704\t            {\n",
      "00705\t        __failure = 7;\n",
      "00706\t        if (!PyErr_Occurred()) {\n",
      "00707\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00708\t                \"Unexpected error in an Op's C code. \"\n",
      "00709\t                \"No Python exception was set.\");\n",
      "00710\t            }\n",
      "00711\t        goto __label_7;};\n",
      "00712\t        }\n",
      "00713\t        if (Nx[1] != Ny[0])\n",
      "00714\t        {\n",
      "00715\t            PyErr_Format(PyExc_ValueError,\n",
      "00716\t                \"Shape mismatch: x has %ld cols (and %ld rows) but y has %ld rows (and %ld cols)\",\n",
      "00717\t                (long int)Nx[1], (long int)Nx[0], (long int)Ny[0], (long int)Ny[1]);\n",
      "00718\t            {\n",
      "00719\t        __failure = 7;\n",
      "00720\t        if (!PyErr_Occurred()) {\n",
      "00721\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00722\t                \"Unexpected error in an Op's C code. \"\n",
      "00723\t                \"No Python exception was set.\");\n",
      "00724\t            }\n",
      "00725\t        goto __label_7;};\n",
      "00726\t        }\n",
      "00727\t        if (Ny[1] != Nz[1])\n",
      "00728\t        {\n",
      "00729\t            PyErr_Format(PyExc_ValueError,\n",
      "00730\t                \"Shape mismatch: y has %ld cols but z has %ld cols\",\n",
      "00731\t                (long int)Ny[1], (long int)Nz[1]);\n",
      "00732\t            {\n",
      "00733\t        __failure = 7;\n",
      "00734\t        if (!PyErr_Occurred()) {\n",
      "00735\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00736\t                \"Unexpected error in an Op's C code. \"\n",
      "00737\t                \"No Python exception was set.\");\n",
      "00738\t            }\n",
      "00739\t        goto __label_7;};\n",
      "00740\t        }\n",
      "00741\t\n",
      "00742\t        // We must not raise an error when Nx[1] == 0. This would disable cases\n",
      "00743\t        // that numpy.dot accept.\n",
      "00744\t        \n",
      "00745\t        /*\n",
      "00746\t        If some matrices are not contiguous on either dimensions,\n",
      "00747\t        or have invalid strides, copy their content into a contiguous one\n",
      "00748\t        */\n",
      "00749\t        if ((Sx[0] < 1) || (Sx[1] < 1) || (Sx[0] MOD type_size) || (Sx[1] MOD type_size)\n",
      "00750\t            || ((Sx[0] != type_size) && (Sx[1] != type_size)))\n",
      "00751\t        {\n",
      "00752\t            PyArrayObject * _x_copy = (PyArrayObject *) PyArray_Copy(V3);\n",
      "00753\t            if (!_x_copy)\n",
      "00754\t                {\n",
      "00755\t        __failure = 7;\n",
      "00756\t        if (!PyErr_Occurred()) {\n",
      "00757\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00758\t                \"Unexpected error in an Op's C code. \"\n",
      "00759\t                \"No Python exception was set.\");\n",
      "00760\t            }\n",
      "00761\t        goto __label_7;}\n",
      "00762\t            Py_XDECREF(V3);\n",
      "00763\t            V3 = _x_copy;\n",
      "00764\t            Sx = PyArray_STRIDES(V3);\n",
      "00765\t        }\n",
      "00766\t\n",
      "00767\t        if ((Sy[0] < 1) || (Sy[1] < 1) || (Sy[0] MOD type_size) || (Sy[1] MOD type_size)\n",
      "00768\t            || ((Sy[0] != type_size) && (Sy[1] != type_size)))\n",
      "00769\t        {\n",
      "00770\t            PyArrayObject * _y_copy = (PyArrayObject *) PyArray_Copy(V5);\n",
      "00771\t            if (!_y_copy)\n",
      "00772\t                {\n",
      "00773\t        __failure = 7;\n",
      "00774\t        if (!PyErr_Occurred()) {\n",
      "00775\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00776\t                \"Unexpected error in an Op's C code. \"\n",
      "00777\t                \"No Python exception was set.\");\n",
      "00778\t            }\n",
      "00779\t        goto __label_7;}\n",
      "00780\t            Py_XDECREF(V5);\n",
      "00781\t            V5 = _y_copy;\n",
      "00782\t            Sy = PyArray_STRIDES(V5);\n",
      "00783\t        }\n",
      "00784\t\n",
      "00785\t        if ((Sz[0] < 1) || (Sz[1] < 1) || (Sz[0] MOD type_size) || (Sz[1] MOD type_size)\n",
      "00786\t            || ((Sz[0] != type_size) && (Sz[1] != type_size)))\n",
      "00787\t        {\n",
      "00788\t            PyArrayObject * _z_copy = (PyArrayObject *) PyArray_Copy(V1);\n",
      "00789\t            if (!_z_copy)\n",
      "00790\t                {\n",
      "00791\t        __failure = 7;\n",
      "00792\t        if (!PyErr_Occurred()) {\n",
      "00793\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00794\t                \"Unexpected error in an Op's C code. \"\n",
      "00795\t                \"No Python exception was set.\");\n",
      "00796\t            }\n",
      "00797\t        goto __label_7;}\n",
      "00798\t            Py_XDECREF(V1);\n",
      "00799\t            V1 = _z_copy;\n",
      "00800\t            Sz = PyArray_STRIDES(V1);\n",
      "00801\t        }\n",
      "00802\t        \n",
      "00803\t        /*\n",
      "00804\t        encode the stride structure of _x,_y,_zout into a single integer\n",
      "00805\t        */\n",
      "00806\t        unit |= ((Sx[1] == type_size || Nx[1]==1) ? 0x0 : (Sx[0] == type_size || Nx[0]==1) ? 0x1 : 0x2) << 8;\n",
      "00807\t        unit |= ((Sy[1] == type_size || Ny[1]==1) ? 0x0 : (Sy[0] == type_size || Ny[0]==1) ? 0x1 : 0x2) << 4;\n",
      "00808\t        unit |= ((Sz[1] == type_size || Nz[1]==1) ? 0x0 : (Sz[0] == type_size || Nz[0]==1) ? 0x1 : 0x2) << 0;\n",
      "00809\t        \n",
      "00810\t        /* create appropriate strides for malformed matrices that are row or column\n",
      "00811\t         * vectors, or empty matrices.\n",
      "00812\t         * In that case, the value of the stride does not really matter, but\n",
      "00813\t         * some versions of BLAS insist that:\n",
      "00814\t         *  - they are not smaller than the number of elements in the array,\n",
      "00815\t         *  - they are not 0.\n",
      "00816\t         */\n",
      "00817\t        sx_0 = (Nx[0] > 1) ? Sx[0]/type_size : (Nx[1] + 1);\n",
      "00818\t        sx_1 = (Nx[1] > 1) ? Sx[1]/type_size : (Nx[0] + 1);\n",
      "00819\t        sy_0 = (Ny[0] > 1) ? Sy[0]/type_size : (Ny[1] + 1);\n",
      "00820\t        sy_1 = (Ny[1] > 1) ? Sy[1]/type_size : (Ny[0] + 1);\n",
      "00821\t        sz_0 = (Nz[0] > 1) ? Sz[0]/type_size : (Nz[1] + 1);\n",
      "00822\t        sz_1 = (Nz[1] > 1) ? Sz[1]/type_size : (Nz[0] + 1);\n",
      "00823\t        \n",
      "00824\t        switch (type_num)\n",
      "00825\t        {\n",
      "00826\t        \n",
      "00827\t            case NPY_FLOAT:\n",
      "00828\t            {\n",
      "00829\t        \n",
      "00830\t                float a = 1.0;\n",
      "00831\t                float b = 0.0;\n",
      "00832\t        \n",
      "00833\t                float* x = (float*)PyArray_DATA(V3);\n",
      "00834\t                float* y = (float*)PyArray_DATA(V5);\n",
      "00835\t                float* z = (float*)PyArray_DATA(V1);\n",
      "00836\t                char N = 'N';\n",
      "00837\t                char T = 'T';\n",
      "00838\t                int Nz0 = Nz[0], Nz1 = Nz[1], Nx1 = Nx[1];\n",
      "00839\t                //std::cerr << (unit/256) MOD 16 << (unit / 16) MOD 16 << unit MOD 16<< '\\n';\n",
      "00840\t                //double t0 = time_time();\n",
      "00841\t                switch(unit)\n",
      "00842\t                {\n",
      "00843\t                    case 0x000: sgemm_(&N, &N, &Nz1, &Nz0, &Nx1, &a, y, &sy_0, x, &sx_0, &b, z, &sz_0); break;\n",
      "00844\t                    case 0x100: sgemm_(&N, &T, &Nz1, &Nz0, &Nx1, &a, y, &sy_0, x, &sx_1, &b, z, &sz_0); break;\n",
      "00845\t                    case 0x010: sgemm_(&T, &N, &Nz1, &Nz0, &Nx1, &a, y, &sy_1, x, &sx_0, &b, z, &sz_0); break;\n",
      "00846\t                    case 0x110: sgemm_(&T, &T, &Nz1, &Nz0, &Nx1, &a, y, &sy_1, x, &sx_1, &b, z, &sz_0); break;\n",
      "00847\t                    case 0x001: sgemm_(&T, &T, &Nz0, &Nz1, &Nx1, &a, x, &sx_0, y, &sy_0, &b, z, &sz_1); break;\n",
      "00848\t                    case 0x101: sgemm_(&N, &T, &Nz0, &Nz1, &Nx1, &a, x, &sx_1, y, &sy_0, &b, z, &sz_1); break;\n",
      "00849\t                    case 0x011: sgemm_(&T, &N, &Nz0, &Nz1, &Nx1, &a, x, &sx_0, y, &sy_1, &b, z, &sz_1); break;\n",
      "00850\t                    case 0x111: sgemm_(&N, &N, &Nz0, &Nz1, &Nx1, &a, x, &sx_1, y, &sy_1, &b, z, &sz_1); break;\n",
      "00851\t                    default: PyErr_SetString(PyExc_ValueError, \"some matrix has no unit stride\"); {\n",
      "00852\t        __failure = 7;\n",
      "00853\t        if (!PyErr_Occurred()) {\n",
      "00854\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00855\t                \"Unexpected error in an Op's C code. \"\n",
      "00856\t                \"No Python exception was set.\");\n",
      "00857\t            }\n",
      "00858\t        goto __label_7;};\n",
      "00859\t                };\n",
      "00860\t                //fprintf(stderr, \"Calling sgemm %i %i %i %i took %f\\n\", unit, Nz1, Nz0, Nx1, time_time() - t0);\n",
      "00861\t        \n",
      "00862\t            }\n",
      "00863\t            break;\n",
      "00864\t            case NPY_DOUBLE:\n",
      "00865\t            {\n",
      "00866\t        \n",
      "00867\t                double a = 1.0;\n",
      "00868\t                double b = 0.0;\n",
      "00869\t        \n",
      "00870\t                double* x = (double*)PyArray_DATA(V3);\n",
      "00871\t                double* y = (double*)PyArray_DATA(V5);\n",
      "00872\t                double* z = (double*)PyArray_DATA(V1);\n",
      "00873\t                char N = 'N';\n",
      "00874\t                char T = 'T';\n",
      "00875\t                int Nz0 = Nz[0], Nz1 = Nz[1], Nx1 = Nx[1];\n",
      "00876\t                //std::cerr << (unit/256) MOD 16 << (unit / 16) MOD 16 << unit MOD 16<< '\\n';\n",
      "00877\t                //double t0 = time_time();\n",
      "00878\t                //fprintf(stderr, \"unit=%x N= %i %i %i S = %i %i %i %i %i %i\\n\", unit,\n",
      "00879\t                //Nz1, Nz0, Nx1,\n",
      "00880\t                //sy_0, sy_1,\n",
      "00881\t                //sx_0, sx_1,\n",
      "00882\t                //sz_0, sz_1\n",
      "00883\t                //);\n",
      "00884\t                switch(unit)\n",
      "00885\t                {\n",
      "00886\t                    case 0x000: dgemm_(&N, &N, &Nz1, &Nz0, &Nx1, &a, y,\n",
      "00887\t                                       &sy_0, x, &sx_0, &b, z, &sz_0); break;\n",
      "00888\t                    case 0x100: dgemm_(&N, &T, &Nz1, &Nz0, &Nx1, &a, y,\n",
      "00889\t                                       &sy_0, x, &sx_1, &b, z, &sz_0); break;\n",
      "00890\t                    case 0x010: dgemm_(&T, &N, &Nz1, &Nz0, &Nx1, &a, y,\n",
      "00891\t                                       &sy_1, x, &sx_0, &b, z, &sz_0); break;\n",
      "00892\t                    case 0x110: dgemm_(&T, &T, &Nz1, &Nz0, &Nx1, &a, y,\n",
      "00893\t                                       &sy_1, x, &sx_1, &b, z, &sz_0); break;\n",
      "00894\t                    case 0x001: dgemm_(&T, &T, &Nz0, &Nz1, &Nx1, &a, x,\n",
      "00895\t                                       &sx_0, y, &sy_0, &b, z, &sz_1); break;\n",
      "00896\t                    case 0x101: dgemm_(&N, &T, &Nz0, &Nz1, &Nx1, &a, x,\n",
      "00897\t                                       &sx_1, y, &sy_0, &b, z, &sz_1); break;\n",
      "00898\t                    case 0x011: dgemm_(&T, &N, &Nz0, &Nz1, &Nx1, &a, x,\n",
      "00899\t                                       &sx_0, y, &sy_1, &b, z, &sz_1); break;\n",
      "00900\t                    case 0x111: dgemm_(&N, &N, &Nz0, &Nz1, &Nx1, &a, x,\n",
      "00901\t                                       &sx_1, y, &sy_1, &b, z, &sz_1); break;\n",
      "00902\t                    default: PyErr_SetString(PyExc_ValueError,\n",
      "00903\t                                             \"some matrix has no unit stride\");\n",
      "00904\t                             {\n",
      "00905\t        __failure = 7;\n",
      "00906\t        if (!PyErr_Occurred()) {\n",
      "00907\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00908\t                \"Unexpected error in an Op's C code. \"\n",
      "00909\t                \"No Python exception was set.\");\n",
      "00910\t            }\n",
      "00911\t        goto __label_7;};\n",
      "00912\t                };\n",
      "00913\t                //fprintf(stderr, \"Calling dgemm %i %i %i %i took %f\\n\",\n",
      "00914\t                //        unit, Nz1, Nz0, Nx1, time_time()- t0);\n",
      "00915\t        \n",
      "00916\t            }\n",
      "00917\t            break;\n",
      "00918\t        }\n",
      "00919\t        __label_7:\n",
      "00920\t\n",
      "00921\tdouble __DUMMY_7;\n",
      "00922\t\n",
      "00923\t}\n",
      "00924\t__label_6:\n",
      "00925\t\n",
      "00926\t        if (V5) {\n",
      "00927\t            Py_XDECREF(V5);\n",
      "00928\t        }\n",
      "00929\t        \n",
      "00930\t    {Py_XDECREF(py_V5);}\n",
      "00931\t    \n",
      "00932\tdouble __DUMMY_6;\n",
      "00933\t\n",
      "00934\t}\n",
      "00935\t__label_4:\n",
      "00936\t\n",
      "00937\t        if (V3) {\n",
      "00938\t            Py_XDECREF(V3);\n",
      "00939\t        }\n",
      "00940\t        \n",
      "00941\t    {Py_XDECREF(py_V3);}\n",
      "00942\t    \n",
      "00943\tdouble __DUMMY_4;\n",
      "00944\t\n",
      "00945\t}\n",
      "00946\t__label_2:\n",
      "00947\t\n",
      "00948\t    if (!__failure) {\n",
      "00949\t      \n",
      "00950\t        {Py_XDECREF(py_V1);}\n",
      "00951\t        if (!V1) {\n",
      "00952\t            Py_INCREF(Py_None);\n",
      "00953\t            py_V1 = Py_None;\n",
      "00954\t        }\n",
      "00955\t        else if ((void*)py_V1 != (void*)V1) {\n",
      "00956\t            py_V1 = (PyObject*)V1;\n",
      "00957\t        }\n",
      "00958\t\n",
      "00959\t        {Py_XINCREF(py_V1);}\n",
      "00960\t\n",
      "00961\t        if (V1 && !PyArray_ISALIGNED((PyArrayObject*) py_V1)) {\n",
      "00962\t            PyErr_Format(PyExc_NotImplementedError,\n",
      "00963\t                         \"c_sync: expected an aligned array, got non-aligned array of type %ld\"\n",
      "00964\t                         \" with %ld dimensions, with 3 last dims \"\n",
      "00965\t                         \"%ld, %ld, %ld\"\n",
      "00966\t                         \" and 3 last strides %ld %ld, %ld.\",\n",
      "00967\t                         (long int) PyArray_TYPE((PyArrayObject*) py_V1),\n",
      "00968\t                         (long int) PyArray_NDIM(V1),\n",
      "00969\t                         (long int) PyArray_NDIM(V1) >= 3 ?\n",
      "00970\t        PyArray_DIMS(V1)[PyArray_NDIM(V1)-3] : -1,\n",
      "00971\t                         (long int) PyArray_NDIM(V1) >= 2 ?\n",
      "00972\t        PyArray_DIMS(V1)[PyArray_NDIM(V1)-2] : -1,\n",
      "00973\t                         (long int) PyArray_NDIM(V1) >= 1 ?\n",
      "00974\t        PyArray_DIMS(V1)[PyArray_NDIM(V1)-1] : -1,\n",
      "00975\t                         (long int) PyArray_NDIM(V1) >= 3 ?\n",
      "00976\t        PyArray_STRIDES(V1)[PyArray_NDIM(V1)-3] : -1,\n",
      "00977\t                         (long int) PyArray_NDIM(V1) >= 2 ?\n",
      "00978\t        PyArray_STRIDES(V1)[PyArray_NDIM(V1)-2] : -1,\n",
      "00979\t                         (long int) PyArray_NDIM(V1) >= 1 ?\n",
      "00980\t        PyArray_STRIDES(V1)[PyArray_NDIM(V1)-1] : -1\n",
      "00981\t        );\n",
      "00982\t            {\n",
      "00983\t        __failure = 2;\n",
      "00984\t        if (!PyErr_Occurred()) {\n",
      "00985\t            PyErr_SetString(PyExc_RuntimeError,\n",
      "00986\t                \"Unexpected error in an Op's C code. \"\n",
      "00987\t                \"No Python exception was set.\");\n",
      "00988\t            }\n",
      "00989\t        goto __label_2;}\n",
      "00990\t        }\n",
      "00991\t        \n",
      "00992\t      PyObject* old = PyList_GET_ITEM(storage_V1, 0);\n",
      "00993\t      {Py_XINCREF(py_V1);}\n",
      "00994\t      PyList_SET_ITEM(storage_V1, 0, py_V1);\n",
      "00995\t      {Py_XDECREF(old);}\n",
      "00996\t    }\n",
      "00997\t    \n",
      "00998\t        if (V1) {\n",
      "00999\t            Py_XDECREF(V1);\n",
      "01000\t        }\n",
      "01001\t        \n",
      "01002\t    {Py_XDECREF(py_V1);}\n",
      "01003\t    \n",
      "01004\tdouble __DUMMY_2;\n",
      "01005\t\n",
      "01006\t}\n",
      "01007\t\n",
      "01008\t            \n",
      "01009\t        if (__failure) {\n",
      "01010\t            // When there is a failure, this code puts the exception\n",
      "01011\t            // in __ERROR.\n",
      "01012\t            PyObject* err_type = NULL;\n",
      "01013\t            PyObject* err_msg = NULL;\n",
      "01014\t            PyObject* err_traceback = NULL;\n",
      "01015\t            PyErr_Fetch(&err_type, &err_msg, &err_traceback);\n",
      "01016\t            if (!err_type) {err_type = Py_None;Py_INCREF(Py_None);}\n",
      "01017\t            if (!err_msg) {err_msg = Py_None; Py_INCREF(Py_None);}\n",
      "01018\t            if (!err_traceback) {err_traceback = Py_None; Py_INCREF(Py_None);}\n",
      "01019\t            PyObject* old_err_type = PyList_GET_ITEM(__ERROR, 0);\n",
      "01020\t            PyObject* old_err_msg = PyList_GET_ITEM(__ERROR, 1);\n",
      "01021\t            PyObject* old_err_traceback = PyList_GET_ITEM(__ERROR, 2);\n",
      "01022\t            PyList_SET_ITEM(__ERROR, 0, err_type);\n",
      "01023\t            PyList_SET_ITEM(__ERROR, 1, err_msg);\n",
      "01024\t            PyList_SET_ITEM(__ERROR, 2, err_traceback);\n",
      "01025\t            {Py_XDECREF(old_err_type);}\n",
      "01026\t            {Py_XDECREF(old_err_msg);}\n",
      "01027\t            {Py_XDECREF(old_err_traceback);}\n",
      "01028\t        }\n",
      "01029\t        // The failure code is returned to index what code block failed.\n",
      "01030\t        return __failure;\n",
      "01031\t        \n",
      "01032\t        }\n",
      "01033\t    };\n",
      "01034\t    }\n",
      "01035\t    \n",
      "01036\t\n",
      "01037\t        static int __struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd_executor(__struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd* self) {\n",
      "01038\t            return self->run();\n",
      "01039\t        }\n",
      "01040\t\n",
      "01041\t        static void __struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd_destructor(void* executor, void* self) {\n",
      "01042\t            delete ((__struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd*)self);\n",
      "01043\t        }\n",
      "01044\t        \n",
      "01045\t//////////////////////\n",
      "01046\t////  Functions\n",
      "01047\t//////////////////////\n",
      "01048\tstatic PyObject * instantiate(PyObject * self, PyObject *argtuple) {\n",
      "01049\t  assert(PyTuple_Check(argtuple));\n",
      "01050\t  if (4 != PyTuple_Size(argtuple)){ \n",
      "01051\t     PyErr_Format(PyExc_TypeError, \"Wrong number of arguments, expected 4, got %i\", (int)PyTuple_Size(argtuple));\n",
      "01052\t     return NULL;\n",
      "01053\t  }\n",
      "01054\t  __struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd* struct_ptr = new __struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd();\n",
      "01055\t  if (struct_ptr->init( PyTuple_GET_ITEM(argtuple, 0),PyTuple_GET_ITEM(argtuple, 1),PyTuple_GET_ITEM(argtuple, 2),PyTuple_GET_ITEM(argtuple, 3) ) != 0) {\n",
      "01056\t    delete struct_ptr;\n",
      "01057\t    return NULL;\n",
      "01058\t  }\n",
      "01059\t  PyObject* thunk = PyCObject_FromVoidPtrAndDesc((void*)(&__struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd_executor), struct_ptr, __struct_compiled_op_e3c8de9d51e298a853a3dc6d24b85ffd_destructor);\n",
      "01060\t  return thunk; }\n",
      "01061\t\n",
      "01062\t//////////////////////\n",
      "01063\t////  Module init\n",
      "01064\t//////////////////////\n",
      "01065\tstatic PyMethodDef MyMethods[] = {\n",
      "01066\t\t{\"instantiate\", instantiate, METH_VARARGS, \"undocumented\"} ,\n",
      "01067\t\t{NULL, NULL, 0, NULL}\n",
      "01068\t};\n",
      "01069\tPyMODINIT_FUNC inite3c8de9d51e298a853a3dc6d24b85ffd(void){\n",
      "01070\t   import_array();\n",
      "01071\t   (void) Py_InitModule(\"e3c8de9d51e298a853a3dc6d24b85ffd\", MyMethods);\n",
      "01072\t}\n",
      "01073\t\n",
      "Problem occurred during compilation with the command line below:\n",
      "C:\\MinGW\\bin\\g++.exe -shared -g -O3 -fno-math-errno -Wno-unused-label -Wno-unused-variable -Wno-write-strings -Wl,-rpath,C:/blaslapack -shared -I[C:\\MinGW]\\include -L[C:\\Anaconda]\\libs -lpython27 -DMS_WIN64 -march=westmere -mmmx -mno-3dnow -msse -msse2 -msse3 -mssse3 -mno-sse4a -mcx16 -msahf -mno-movbe -mno-aes -mno-sha -mno-pclmul -mpopcnt -mno-abm -mno-lwp -mno-fma -mno-fma4 -mno-xop -mno-bmi -mno-bmi2 -mno-tbm -mno-avx -mno-avx2 -msse4.2 -msse4.1 -mno-lzcnt -mno-rtm -mno-hle -mno-rdrnd -mno-f16c -mno-fsgsbase -mno-rdseed -mno-prfchw -mno-adx -mfxsr -mno-xsave -mno-xsaveopt -mno-avx512f -mno-avx512er -mno-avx512cd -mno-avx512pf -mno-prefetchwt1 -mno-clflushopt -mno-xsavec -mno-xsaves -mno-avx512dq -mno-avx512bw -mno-avx512vl -mno-avx512ifma -mno-avx512vbmi -mno-clwb -mno-pcommit -mno-mwaitx --param l1-cache-size=32 --param l1-cache-line-size=64 --param l2-cache-size=3072 -mtune=westmere -DNPY_NO_DEPRECATED_API=NPY_1_7_API_VERSION -m64 -DMS_WIN64 -IC:\\Anaconda\\lib\\site-packages\\numpy\\core\\include -IC:\\Anaconda\\include -IC:\\Anaconda\\lib\\site-packages\\theano\\gof -o C:\\Users\\AlexGrinch\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_37_Stepping_5_GenuineIntel-2.7.11-64\\tmpxnpkiu\\e3c8de9d51e298a853a3dc6d24b85ffd.pyd C:\\Users\\AlexGrinch\\AppData\\Local\\Theano\\compiledir_Windows-10-10.0.10586-Intel64_Family_6_Model_37_Stepping_5_GenuineIntel-2.7.11-64\\tmpxnpkiu\\mod.cpp -LC:/blaslapack -LC:\\Anaconda\\libs -LC:\\Anaconda -lblas -lpython27\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "('The following error happened while compiling the node', Dot22(Reshape{2}.0, hidden_dense_layer.W), '\\n', 'Compilation failed (return status=1): C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: skipping incompatible C:/blaslapack/libblas.dll when searching for -lblas\\r. C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: skipping incompatible C:/blaslapack/libblas.dll when searching for -lblas\\r. C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: cannot find -lblas\\r. collect2.exe: error: ld returned 1 exit status\\r. ', '[Dot22(<TensorType(float32, matrix)>, hidden_dense_layer.W)]')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-53-81227a628e74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#function that computes loss and updates weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtrain_fun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mupdates\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mupdates_sgd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#function that just computes accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0maccuracy_fun\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minput_X\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtarget_y\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\function.pyc\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    320\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    321\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 322\u001b[1;33m                    output_keys=output_keys)\n\u001b[0m\u001b[0;32m    323\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\pfunc.pyc\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m    478\u001b[0m                          \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m                          \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m                          output_keys=output_keys)\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input, output_keys)\u001b[0m\n\u001b[0;32m   1777\u001b[0m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1778\u001b[0m                    \u001b[0moutput_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1779\u001b[1;33m             defaults)\n\u001b[0m\u001b[0;32m   1780\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1781\u001b[0m     \u001b[0mt2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\compile\\function_module.pyc\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self, input_storage, trustme, storage_map)\u001b[0m\n\u001b[0;32m   1641\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1642\u001b[0m             _fn, _i, _o = self.linker.make_thunk(\n\u001b[1;32m-> 1643\u001b[1;33m                 input_storage=input_storage_lists, storage_map=storage_map)\n\u001b[0m\u001b[0;32m   1644\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1645\u001b[0m             \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraceback\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlimit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlimit_orig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\link.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m    688\u001b[0m         return self.make_all(input_storage=input_storage,\n\u001b[0;32m    689\u001b[0m                              \u001b[0moutput_storage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 690\u001b[1;33m                              storage_map=storage_map)[:3]\n\u001b[0m\u001b[0;32m    691\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    692\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmake_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\vm.pyc\u001b[0m in \u001b[0;36mmake_all\u001b[1;34m(self, profiler, input_storage, output_storage, storage_map)\u001b[0m\n\u001b[0;32m   1003\u001b[0m                                                  \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m                                                  \u001b[0mcompute_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1005\u001b[1;33m                                                  no_recycling))\n\u001b[0m\u001b[0;32m   1006\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mthunks\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'lazy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1007\u001b[0m                     \u001b[1;31m# We don't want all ops maker to think about lazy Ops.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    976\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    977\u001b[0m                 return self.make_c_thunk(node, storage_map, compute_map,\n\u001b[1;32m--> 978\u001b[1;33m                                          no_recycling)\n\u001b[0m\u001b[0;32m    979\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mNotImplementedError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMethodNotDefined\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m                 \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Falling back on perform'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\op.pyc\u001b[0m in \u001b[0;36mmake_c_thunk\u001b[1;34m(self, node, storage_map, compute_map, no_recycling)\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Trying CLinker.make_thunk'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m         outputs = cl.make_thunk(input_storage=node_input_storage,\n\u001b[1;32m--> 881\u001b[1;33m                                 output_storage=node_output_storage)\n\u001b[0m\u001b[0;32m    882\u001b[0m         \u001b[0mfill_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_input_filters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnode_output_filters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    883\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36mmake_thunk\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1198\u001b[0m         cthunk, in_storage, out_storage, error_storage = self.__compile__(\n\u001b[0;32m   1199\u001b[0m             \u001b[0minput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1200\u001b[1;33m             keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1202\u001b[0m         \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_CThunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcthunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minit_tasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merror_storage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36m__compile__\u001b[1;34m(self, input_storage, output_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1141\u001b[0m                                     \u001b[0moutput_storage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1142\u001b[0m                                     \u001b[0mstorage_map\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1143\u001b[1;33m                                     keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1144\u001b[0m         return (thunk,\n\u001b[0;32m   1145\u001b[0m                 [link.Container(input, storage) for input, storage in\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36mcthunk_factory\u001b[1;34m(self, error_storage, in_storage, out_storage, storage_map, keep_lock)\u001b[0m\n\u001b[0;32m   1593\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1594\u001b[0m             module = get_module_cache().module_from_key(\n\u001b[1;32m-> 1595\u001b[1;33m                 key=key, lnk=self, keep_lock=keep_lock)\n\u001b[0m\u001b[0;32m   1596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1597\u001b[0m         \u001b[0mvars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0morphans\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\cmodule.pyc\u001b[0m in \u001b[0;36mmodule_from_key\u001b[1;34m(self, key, lnk, keep_lock)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m                 \u001b[0mlocation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlimport_workdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m                 \u001b[0mmodule\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlnk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile_cmodule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1143\u001b[0m                 \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__file__\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m                 \u001b[1;32massert\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\cc.pyc\u001b[0m in \u001b[0;36mcompile_cmodule\u001b[1;34m(self, location)\u001b[0m\n\u001b[0;32m   1504\u001b[0m                 \u001b[0mlib_dirs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib_dirs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1505\u001b[0m                 \u001b[0mlibs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlibs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1506\u001b[1;33m                 preargs=preargs)\n\u001b[0m\u001b[0;32m   1507\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1508\u001b[0m             \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfgraph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\theano\\gof\\cmodule.pyc\u001b[0m in \u001b[0;36mcompile_str\u001b[1;34m(module_name, src_code, location, include_dirs, lib_dirs, libs, preargs, py_module, hide_symbols)\u001b[0m\n\u001b[0;32m   2202\u001b[0m             \u001b[1;31m# difficult to read.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2203\u001b[0m             raise Exception('Compilation failed (return status=%s): %s' %\n\u001b[1;32m-> 2204\u001b[1;33m                             (status, compile_stderr.replace('\\n', '. ')))\n\u001b[0m\u001b[0;32m   2205\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompilation_warning\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcompile_stderr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2206\u001b[0m             \u001b[1;31m# Print errors just below the command line.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: ('The following error happened while compiling the node', Dot22(Reshape{2}.0, hidden_dense_layer.W), '\\n', 'Compilation failed (return status=1): C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: skipping incompatible C:/blaslapack/libblas.dll when searching for -lblas\\r. C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: skipping incompatible C:/blaslapack/libblas.dll when searching for -lblas\\r. C:/MinGW/bin/../lib/gcc/x86_64-w64-mingw32/5.2.0/../../../../x86_64-w64-mingw32/bin/ld.exe: cannot find -lblas\\r. collect2.exe: error: ld returned 1 exit status\\r. ', '[Dot22(<TensorType(float32, matrix)>, hidden_dense_layer.W)]')"
     ]
    }
   ],
   "source": [
    "#function that computes loss and updates weights\n",
    "train_fun = theano.function([input_X,target_y],[loss,accuracy],updates= updates_sgd)\n",
    "\n",
    "#function that just computes accuracy\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### That's all, now let's train it!\n",
    "* We got a lot of data, so it's recommended that you use SGD\n",
    "* So let's implement a function that splits the training sample into minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# An auxilary function that returns mini-batches for neural network training\n",
    "\n",
    "#Parameters\n",
    "# X - a tensor of images with shape (many, 1, 28, 28), e.g. X_train\n",
    "# y - a vector of answers for corresponding images e.g. Y_train\n",
    "#batch_size - a single number - the intended size of each batches\n",
    "\n",
    "#What do need to implement\n",
    "# 1) Shuffle data\n",
    "# - Gotta shuffle X and y the same way not to break the correspondence between X_i and y_i\n",
    "# 3) Split data into minibatches of batch_size\n",
    "# - If data size is not a multiple of batch_size, make one last batch smaller.\n",
    "# 4) return a list (or an iterator) of pairs\n",
    "# - (подгруппа картинок, ответы из y на эту подгруппу)\n",
    "def iterate_minibatches(X, y, batchsize):\n",
    "    \n",
    "    <return an iterable of (X_batch, y_batch)  batches of images and answers for them>\n",
    "    \n",
    "        \n",
    "        \n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "#\n",
    "# You feel lost and wish you stayed home tonight?\n",
    "# Go search for a similar function at\n",
    "# https://github.com/Lasagne/Lasagne/blob/master/examples/mnist.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "num_epochs = 100 #amount of passes through the data\n",
    "\n",
    "batch_size = 50 #number of samples processed at each function call\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 99:\n",
    "    print \"Achievement unlocked: 80lvl Warlock!\"\n",
    "else:\n",
    "    print \"We need more magic!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A better network\n",
    "\n",
    "\n",
    "* The quest is to create a network that gets at least 99% at test set\n",
    " * In case you tried several architectures and have a __detailed__ report - 97.5% \"is fine too\". \n",
    " \n",
    "__ There is a mini-report at the end that you will have to fill in. We recommend to read it first and fill in while you are iterating. __\n",
    " \n",
    "\n",
    "## Tips on what can be done:\n",
    "\n",
    "\n",
    "\n",
    " * Network size\n",
    "   * MOAR neurons, \n",
    "   * MOAR layers, \n",
    "   * Пх'нглуи мглв'нафх Ктулху Р'льех вгах'нагл фхтагн! \n",
    "   \n",
    "   \n",
    "   \n",
    " * Regularize to prevent overfitting\n",
    "   * Add some L2 weight norm to the loss function, theano will do the rest\n",
    "   * Can be done manually or via - http://lasagne.readthedocs.org/en/latest/modules/regularization.html\n",
    "   \n",
    "   \n",
    "   \n",
    " * Better optimization - rmsprop, nesterov_momentum, adadelta, adagrad and so on.\n",
    "   * Converge faster and sometimes reach better optima\n",
    "   * It might make sense to tweak learning rate, other learning parameters, batch size and number of epochs\n",
    "   \n",
    "   \n",
    "   \n",
    " * Dropout - to prevent overfitting\n",
    "   * `lasagne.layers.DropoutLayer(prev_layer, p=probability_to_zero_out)`\n",
    "   \n",
    "   \n",
    "   \n",
    " * Convolution layers\n",
    "   * `network = lasagne.layers.Conv2DLayer(prev_layer,`\n",
    "    `                       num_filters = n_neurons,`\n",
    "    `                        filter_size = (filter width, filter height),`\n",
    "    `                        nonlinearity = some_nonlinearity)`\n",
    "   * Warning! Training convolutional networks can take long without GPU.\n",
    "     * If you are CPU-only, we still recomment to try a simple convolutional architecture\n",
    "     * a perfect option is if you can set it up to run at nighttime and check it up at the morning.\n",
    " \n",
    " * Plenty other layers and architectures\n",
    "   * http://lasagne.readthedocs.org/en/latest/modules/layers.html\n",
    "   * batch normalization, pooling, etc\n",
    "   \n",
    "   \n",
    " * Nonlinearities in the hidden layers\n",
    "   * tanh, relu, leaky relu, etc\n",
    "   \n",
    " \n",
    " \n",
    "   \n",
    "There is a template for your solution below that you can opt to use or throw away and write it your way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from mnist import load_dataset\n",
    "X_train,y_train,X_val,y_val,X_test,y_test = load_dataset()\n",
    "\n",
    "print X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "\n",
    "#input dimention (None means \"Arbitrary\" and only works at  the first axes [samples])\n",
    "input_shape = [None,1,28,28]\n",
    "\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input layer (auxilary)\n",
    "input_layer = lasagne.layers.InputLayer(shape = input_shape,input_var=input_X)\n",
    "\n",
    "<student.code_neural_network_architecture()>\n",
    "\n",
    "dense_output = <your network output>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Network predictions (theano-transformation)\n",
    "y_predicted = lasagne.layers.get_output(dense_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All weights (shared-varaibles)\n",
    "# \"trainable\" flag means not to return auxilary params like batch mean (for batch normalization)\n",
    "all_weights = lasagne.layers.get_all_params(dense_output,trainable=True)\n",
    "print all_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loss function\n",
    "loss = <loss function>\n",
    "\n",
    "#<optionally add regularization>\n",
    "\n",
    "accuracy = <mean accuracy score for evaluation> \n",
    "\n",
    "#weight updates\n",
    "updates = <try different update methods>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A function that accepts X and y, returns loss functions and performs weight updates\n",
    "train_fun = theano.function([input_X,target_y],[loss,accuracy],updates= updates_sgd)\n",
    "\n",
    "#A function that just computes accuracy given X and y\n",
    "accuracy_fun = theano.function([input_X,target_y],accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#итерации обучения\n",
    "\n",
    "num_epochs = <how many times to iterate over the entire training set>\n",
    "\n",
    "batch_size = <how many samples are processed at a single function call>\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    for batch in iterate_minibatches(X_train, y_train,batch_size):\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    \n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "        epoch + 1, num_epochs, time.time() - start_time))\n",
    "\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(\n",
    "        train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(\n",
    "        val_acc / val_batches * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_acc = 0\n",
    "test_batches = 0\n",
    "for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "    inputs, targets = batch\n",
    "    acc = accuracy_fun(inputs, targets)\n",
    "    test_acc += acc\n",
    "    test_batches += 1\n",
    "print(\"Final results:\")\n",
    "print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "    test_acc / test_batches * 100))\n",
    "\n",
    "if test_acc / test_batches * 100 > 99:\n",
    "    print \"Achievement unlocked: 80lvl Warlock!\"\n",
    "else:\n",
    "    print \"We need more magic!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report\n",
    "\n",
    "All creative approaches are highly welcome, but at the very least it would be great to mention\n",
    "* the idea;\n",
    "* brief history of tweaks and improvements;\n",
    "* what is the final architecture and why?\n",
    "* what is the training method and, again, why?\n",
    "* Any regularizations and other techniques applied and their effects;\n",
    "\n",
    "\n",
    "There is no need to write strict mathematical proofs (unless you want to).\n",
    " * \"I tried this, this and this, and the second one turned out to be better. And i just didn't like the name of that one\" - OK, but can be better\n",
    " * \"I have analized these and these articles|sources|blog posts, tried that and that to adapt them to my problem and the conclusions are such and such\" - the ideal one\n",
    " * \"I took that code that demo without understanding it, but i'll never confess that and instead i'll make up some pseudoscientific explaination\" - __not_ok__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hi, my name is `___ ___`, and here's my story\n",
    "\n",
    "A long ago in a galaxy far far away, when it was still more than an hour before deadline, i got an idea:\n",
    "\n",
    "##### I gonna build a neural network, that\n",
    "* brief text on what was\n",
    "* the original idea\n",
    "* and why it was so\n",
    "\n",
    "How could i be so naive?!\n",
    "\n",
    "##### One day, with no signs of warning,\n",
    "This thing has finally converged and\n",
    "* Some explaination about what were the results,\n",
    "* what worked and what didn't\n",
    "* most importantly - what next steps were taken, if any\n",
    "* and what were their respective outcomes\n",
    "\n",
    "##### Finally, after __  iterations, __ mugs of [tea/coffee]\n",
    "* what was the final architecture\n",
    "* as well as training method and tricks\n",
    "\n",
    "That, having wasted ____ [minutes, hours or days] of my life training, got\n",
    "\n",
    "* accuracy on training: __\n",
    "* accuracy on validation: __\n",
    "* accuracy on test: __\n",
    "\n",
    "\n",
    "[an optional afterword and mortal curses on assignment authors]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
